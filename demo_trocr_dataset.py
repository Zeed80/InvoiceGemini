#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥—É–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ TrOCR

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TrOCRDatasetPreparator
–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.
"""

import os
import logging
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('trocr_dataset_demo.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è TrOCR Dataset Preparator")
    print("=" * 50)
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å
        from app.training.trocr_dataset_preparator import (
            TrOCRDatasetPreparator, 
            TrOCRDatasetConfig,
            create_synthetic_trocr_dataset
        )
        
        print("‚úÖ –ú–æ–¥—É–ª—å TrOCR Dataset Preparator —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = TrOCRDatasetConfig(
            model_name="microsoft/trocr-base-stage1",
            max_target_length=128,
            image_size=(384, 384),
            enable_augmentation=True
        )
        
        print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {config.model_name}")
        print(f"   ‚Ä¢ –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {config.max_target_length}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {config.image_size}")
        print(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {config.enable_augmentation}")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1: –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        print("\nüé® –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1: –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç")
        print("-" * 30)
        
        output_dir = "data/demo_trocr_dataset"
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ—Ä
        preparator = TrOCRDatasetPreparator(config)
        
        # –†—É—Å—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        russian_texts = [
            "–û–û–û \"–†–æ–º–∞—à–∫–∞\"",
            "–°—á–µ—Ç-—Ñ–∞–∫—Ç—É—Ä–∞ ‚Ññ",
            "–î–∞—Ç–∞:",
            "–ü–æ—Å—Ç–∞–≤—â–∏–∫:",
            "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å:", 
            "–°—É–º–º–∞ –∫ –æ–ø–ª–∞—Ç–µ:",
            "–ù–î–° 20%:",
            "–ò—Ç–æ–≥–æ:",
            "–ò–ù–ù:",
            "–ö–ü–ü:",
            "–ë–∞–Ω–∫:",
            "–ë–ò–ö:",
            "–†–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç:",
            "–ö–æ—Ä—Ä. —Å—á–µ—Ç:",
            "–î–∏—Ä–µ–∫—Ç–æ—Ä",
            "–ì–ª–∞–≤–Ω—ã–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä"
        ]
        
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        synthetic_datasets = preparator.prepare_synthetic_dataset(
            output_path=output_dir + "/synthetic",
            num_samples=50,  # –ù–µ–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –¥–µ–º–æ
            text_sources=russian_texts
        )
        
        print("‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω:")
        for split, path in synthetic_datasets.items():
            print(f"   ‚Ä¢ {split}: {path}")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        print("\nüìä –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ")
        print("-" * 40)
        
        try:
            dataset_info = preparator.get_dataset_info(output_dir + "/synthetic")
            print("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
            print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {dataset_info['statistics']['total_samples']}")
            print(f"   ‚Ä¢ Splits: {list(dataset_info['statistics']['splits'].keys())}")
            print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–º–∏–Ω/–º–∞–∫—Å/—Å—Ä–µ–¥): {dataset_info['statistics']['text_lengths']['min']}/{dataset_info['statistics']['text_lengths']['max']}/{dataset_info['statistics']['text_lengths']['avg']:.1f}")
            print(f"   ‚Ä¢ –°–æ–∑–¥–∞–Ω: {dataset_info['created_at']}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ: {e}")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 3: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        print("\nüíæ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 3: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        print("-" * 35)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            train_dataset = preparator.load_prepared_dataset(
                output_dir + "/synthetic", 
                split="train"
            )
            
            if hasattr(train_dataset, '__len__'):
                print(f"‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(train_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä
                if len(train_dataset) > 0:
                    try:
                        first_sample = train_dataset[0]
                        print("üìã –ü–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä:")
                        if isinstance(first_sample, dict):
                            for key, value in first_sample.items():
                                if key == "pixel_values" and hasattr(value, 'shape'):
                                    print(f"   ‚Ä¢ {key}: tensor{value.shape}")
                                elif key == "labels" and hasattr(value, 'shape'):
                                    print(f"   ‚Ä¢ {key}: tensor{value.shape}")
                                else:
                                    print(f"   ‚Ä¢ {key}: {str(value)[:100]}...")
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞: {e}")
            else:
                print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω (—Ñ–æ—Ä–º–∞—Ç: {type(train_dataset)})")
                
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç: {e}")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 4: –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è
        print("\nüõ†Ô∏è –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 4: –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è")
        print("-" * 40)
        
        simple_datasets = create_synthetic_trocr_dataset(
            output_path=output_dir + "/simple_synthetic",
            num_samples=20,
            config=config
        )
        
        print("‚úÖ –ü—Ä–æ—Å—Ç–æ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω:")
        for split, path in simple_datasets.items():
            print(f"   ‚Ä¢ {split}: {path}")
        
        print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        print(f"   ‚Ä¢ –õ–æ–≥–∏: trocr_dataset_demo.log")
        print(f"   ‚Ä¢ –î–∞—Ç–∞—Å–µ—Ç—ã: {output_dir}")
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥—É–ª—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –º–µ—Å—Ç–µ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def demo_configuration():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
    
    print("\n‚öôÔ∏è –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π TrOCR")
    print("-" * 40)
    
    try:
        from app.training.trocr_dataset_preparator import TrOCRDatasetConfig
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        printed_config = TrOCRDatasetConfig(
            model_name="microsoft/trocr-base-printed",
            max_target_length=64,
            image_size=(224, 224),
            enable_augmentation=False
        )
        
        print("üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {printed_config.model_name}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {printed_config.image_size}")
        print(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {printed_config.enable_augmentation}")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        handwritten_config = TrOCRDatasetConfig(
            model_name="microsoft/trocr-base-handwritten",
            max_target_length=256,
            image_size=(448, 448),
            enable_augmentation=True,
            brightness_range=(0.5, 1.5),
            gaussian_blur_prob=0.5
        )
        
        print("\n‚úçÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {handwritten_config.model_name}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {handwritten_config.image_size}")
        print(f"   ‚Ä¢ –Ø—Ä–∫–æ—Å—Ç—å: {handwritten_config.brightness_range}")
        print(f"   ‚Ä¢ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º—ã—Ç–∏—è: {handwritten_config.gaussian_blur_prob}")
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")


if __name__ == "__main__":
    main()
    demo_configuration() 