"""
–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö LLM –ø–ª–∞–≥–∏–Ω–æ–≤
"""
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Union
import os
import json
import re
from PIL import Image

# –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å torch, –Ω–æ –¥–µ–ª–∞–µ–º —ç—Ç–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("‚ö†Ô∏è PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. LLM –ø–ª–∞–≥–∏–Ω—ã –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ.")

from ..base_processor import BaseProcessor

class LLMProviderConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ LLM"""
    def __init__(self, name: str, display_name: str, models: List[str], 
                 requires_api_key: bool = True, api_key_name: str = None,
                 default_model: str = None, supports_vision: bool = True):
        self.name = name
        self.display_name = display_name
        self.models = models
        self.requires_api_key = requires_api_key
        self.api_key_name = api_key_name or f"{name.upper()}_API_KEY"
        self.default_model = default_model or (models[0] if models else None)
        self.supports_vision = supports_vision

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
LLM_PROVIDERS = {
    "openai": LLMProviderConfig(
        name="openai",
        display_name="OpenAI (ChatGPT)",
        models=[
            "gpt-4o",
            "gpt-4o-mini", 
            "gpt-4-turbo",
            "gpt-4",
            "gpt-3.5-turbo"
        ],
        default_model="gpt-4o",
        supports_vision=True
    ),
    "anthropic": LLMProviderConfig(
        name="anthropic", 
        display_name="Anthropic (Claude)",
        models=[
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307"
        ],
        default_model="claude-3-5-sonnet-20241022",
        supports_vision=True
    ),
    "google": LLMProviderConfig(
        name="google",
        display_name="Google (Gemini)",
        models=[
            "models/gemini-2.0-flash-exp",
            "models/gemini-1.5-pro-latest",
            "models/gemini-1.5-flash-latest",
            "models/gemini-1.5-pro-002",
            "models/gemini-1.5-flash-002"
        ],
        default_model="models/gemini-2.0-flash-exp",
        supports_vision=True
    ),
    "mistral": LLMProviderConfig(
        name="mistral",
        display_name="Mistral AI",
        models=[
            "mistral-large-latest",
            "mistral-medium-latest", 
            "mistral-small-latest",
            "pixtral-12b-2409"
        ],
        default_model="mistral-large-latest",
        supports_vision=True
    ),
    "deepseek": LLMProviderConfig(
        name="deepseek",
        display_name="DeepSeek",
        models=[
            "deepseek-chat",
            "deepseek-coder"
        ],
        default_model="deepseek-chat", 
        supports_vision=False
    ),
    "xai": LLMProviderConfig(
        name="xai",
        display_name="xAI (Grok)",
        models=[
            "grok-beta",
            "grok-vision-beta"
        ],
        default_model="grok-vision-beta",
        supports_vision=True
    ),
    "ollama": LLMProviderConfig(
        name="ollama",
        display_name="Ollama (–õ–æ–∫–∞–ª—å–Ω–æ)",
        models=[
            "llama3.2-vision:11b",
            "llama3.2:3b",
            "llama3.1:8b",
            "llama3.1:70b",
            "mistral:7b",
            "qwen2.5:7b"
        ],
        default_model="llama3.2-vision:11b",
        requires_api_key=False,
        supports_vision=True
    )
}

class BaseLLMPlugin(BaseProcessor):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö LLM –ø–ª–∞–≥–∏–Ω–æ–≤.
    –†–∞—Å—à–∏—Ä—è–µ—Ç BaseProcessor —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é –¥–ª—è LLM.
    """
    
    def __init__(self, provider_name: str, model_name: str = None, api_key: str = None, **kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –ø–ª–∞–≥–∏–Ω–∞.
        
        Args:
            provider_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (openai, anthropic, google, etc.)
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default)
            api_key: API –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–ª–∞–≥–∏–Ω–∞
        """
        self.provider_name = provider_name
        self.provider_config = LLM_PROVIDERS.get(provider_name)
        
        if not self.provider_config:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä LLM: {provider_name}")
        
        self.model_name = model_name or self.provider_config.default_model
        self.api_key = api_key
        self.client = None
        self.is_loaded = False
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.generation_config = {
            "max_tokens": 4096,
            "temperature": 0.1,
            "top_p": 0.9,
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        self.generation_config.update(kwargs.get("generation_config", {}))
        
        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω LLM –ø–ª–∞–≥–∏–Ω: {self.provider_config.display_name} - {self.model_name}")
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Ç BaseProcessor
    @abstractmethod
    def process_image(self, image_path, ocr_lang=None, custom_prompt=None):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        pass
    
    def supports_training(self) -> bool:
        """LLM –ø–ª–∞–≥–∏–Ω—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –æ–±—É—á–µ–Ω–∏–µ."""
        return True
    
    def get_trainer_class(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∞—Å—Å LLMTrainer."""
        try:
            from .llm_trainer import LLMTrainer
            return LLMTrainer
        except ImportError:
            print("‚ö†Ô∏è LLMTrainer –µ—â–µ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
            return None
    
    def get_model_type(self) -> str:
        return f"llm_{self.provider_name}"
    
    def get_full_prompt(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω–≤–æ–π—Å–æ–≤."""
        return self.create_invoice_prompt()
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è LLM –º–µ—Ç–æ–¥—ã
    @abstractmethod
    def load_model(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        pass
    
    @abstractmethod
    def generate_response(self, prompt: str, image_path: str = None, image_context: str = "") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
            image_context: –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ/OCR —Ç–µ–∫—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            str: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        pass
    
    def get_training_config(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        –î–ª—è –≤–Ω–µ—à–Ω–∏—Ö API –æ–±—ã—á–Ω–æ –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ.
        
        Returns:
            dict: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        return {
            "provider": self.provider_name,
            "model": self.model_name,
            "supports_fine_tuning": False,
            "generation_config": self.generation_config
        }
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    def preprocess_image_for_llm(self, image_path: str) -> Image.Image:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è LLM.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            
        Returns:
            PIL.Image: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        try:
            image = Image.open(image_path)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            return image
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            return Image.new('RGB', (100, 100), color='white')
    
    def extract_text_from_image(self, image_path: str, ocr_lang: str = "rus+eng") -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é OCR.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            ocr_lang: –Ø–∑—ã–∫–∏ –¥–ª—è OCR
            
        Returns:
            str: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            import pytesseract
            image = self.preprocess_image_for_llm(image_path)
            text = pytesseract.image_to_string(image, lang=ocr_lang)
            return text.strip()
        except ImportError:
            print("‚ö†Ô∏è pytesseract –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
            return "OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pytesseract"
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ OCR: {e}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
    
    def create_invoice_prompt(self, custom_prompt: Optional[str] = None, include_context_fields: bool = True) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω–≤–æ–π—Å–∞.
        
        Args:
            custom_prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            include_context_fields: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–æ–ª—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            
        Returns:
            str: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        if custom_prompt:
            return custom_prompt
        
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        base_prompt = """–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é —Å—á–µ—Ç–æ–≤-—Ñ–∞–∫—Ç—É—Ä –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏ –∏–∑ –Ω–µ–≥–æ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.

–§–æ—Ä–º–∞—Ç –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–ª—è (–≤–∫–ª—é—á–∞–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):"""

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        fields_json = {}
        if include_context_fields:
            try:
                from ..settings_manager import settings_manager
                table_fields = settings_manager.get_table_fields()
                if table_fields:
                    fields_json = {field['name']: field.get('description', '') for field in table_fields}
            except:
                pass
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        if not fields_json:
            fields_json = {
                "–ü–æ—Å—Ç–∞–≤—â–∏–∫": "–Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏-–ø–æ—Å—Ç–∞–≤—â–∏–∫–∞",
                "–ò–ù–ù –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞": "–ò–ù–ù –≤ —Ñ–æ—Ä–º–∞—Ç–µ 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä",
                "–ö–ü–ü –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞": "–ö–ü–ü –≤ —Ñ–æ—Ä–º–∞—Ç–µ 9 —Ü–∏—Ñ—Ä",
                "–ê–¥—Ä–µ—Å –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞": "–ø–æ–ª–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å",
                "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å": "–Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏-–ø–æ–∫—É–ø–∞—Ç–µ–ª—è",
                "–ò–ù–ù –ø–æ–∫—É–ø–∞—Ç–µ–ª—è": "–ò–ù–ù –≤ —Ñ–æ—Ä–º–∞—Ç–µ 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä",
                "–ö–ü–ü –ø–æ–∫—É–ø–∞—Ç–µ–ª—è": "–ö–ü–ü –≤ —Ñ–æ—Ä–º–∞—Ç–µ 9 —Ü–∏—Ñ—Ä",
                "–ê–¥—Ä–µ—Å –ø–æ–∫—É–ø–∞—Ç–µ–ª—è": "–ø–æ–ª–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å",
                "‚Ññ –°—á–µ—Ç–∞": "–Ω–æ–º–µ—Ä —Å—á–µ—Ç–∞ —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ",
                "–î–∞—Ç–∞ —Å—á–µ—Ç–∞": "–¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY",
                "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã": "—Å—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω",
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "–æ–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥",
                "–¢–æ–≤–∞—Ä—ã": "—Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏ —Ü–µ–Ω–∞–º–∏",
                "–°—É–º–º–∞ –±–µ–∑ –ù–î–°": "—Å—É–º–º–∞ –¥–æ –ù–î–° —á–∏—Å–ª–æ–º",
                "–ù–î–° %": "—Å—Ç–∞–≤–∫–∞ –ù–î–° —á–∏—Å–ª–æ–º",
                "–°—É–º–º–∞ –ù–î–°": "—Å—É–º–º–∞ –ù–î–° —á–∏—Å–ª–æ–º",
                "–°—É–º–º–∞ —Å –ù–î–°": "–∏—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ —á–∏—Å–ª–æ–º",
                "–í–∞–ª—é—Ç–∞": "RUB/USD/EUR –∏ —Ç.–¥.",
                "–ë–∞–Ω–∫": "–Ω–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ",
                "–ë–ò–ö": "–ë–ò–ö –±–∞–Ω–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 9 —Ü–∏—Ñ—Ä",
                "–†/—Å": "—Ä–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ 20 —Ü–∏—Ñ—Ä",
                "–ö/—Å": "–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç—Å–∫–∏–π —Å—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ 20 —Ü–∏—Ñ—Ä",
                "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏": "–ª—é–±–∞—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        json_structure = "{\n"
        for field_name, description in fields_json.items():
            json_structure += f'  "{field_name}": "{description}",\n'
        json_structure = json_structure.rstrip(',\n') + "\n}"
        
        instructions = """

–í–∞–∂–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –ü—Ä–µ–¥—Å—Ç–∞–≤—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¢–û–õ–¨–ö–û –≤ –≤–∏–¥–µ JSON, –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏ –ø–æ—Å–ª–µ.
2. –°–æ—Ö—Ä–∞–Ω—è–π —Ç–æ—á–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞.
3. –í—ã—á–∏—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –æ–ø–∏—Å–∞–Ω–∏—è.
4. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —á–∏—Å–ª–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤.
5. –î–ª—è –ø–æ–ª–µ–π —Å —á–∏—Å–ª–∞–º–∏ (—Å—É–º–º—ã, –ò–ù–ù, –ö–ü–ü, —Å—á–µ—Ç–∞) —É–¥–∞–ª–∏ –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–∫—É –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –¥—Ä–æ–±–Ω—ã—Ö —á–∏—Å–µ–ª.
6. –î–∞—Ç—ã –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏ –∫ —Ñ–æ—Ä–º–∞—Ç—É DD.MM.YYYY.
7. –ï—Å–ª–∏ –∫–∞–∫–æ–µ-—Ç–æ –ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ, –Ω–µ –≤–∫–ª—é—á–∞–π –µ–≥–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
8. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–º –∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–º –∫ –¥–µ—Ç–∞–ª—è–º."""

        return base_prompt + "\n\n" + json_structure + instructions
    
    def parse_llm_response(self, response: str) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –¥–∞–Ω–Ω—ã–µ.
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç LLM
            
        Returns:
            dict: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ API
            if self._is_error_response(response):
                error_msg = self._extract_error_message(response)
                print(f"‚ùå –û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫—É API: {error_msg}")
                return {"error": error_msg, "note_gemini": f"–û—à–∏–±–∫–∞ API {self.provider_name}: {error_msg}"}
            
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
            cleaned_response = self._clean_json_string(response)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON
            json_match = re.search(r'\{[\s\S]*\}', cleaned_response)
            if json_match:
                json_str = json_match.group()
                data = json.loads(json_str)
                return self._normalize_invoice_data(data)
            else:
                print("‚ö†Ô∏è JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ LLM")
                print(f"–û—Ç–≤–µ—Ç LLM: {response[:300]}...")
                return {"error": "JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ", "raw_response": response[:500]}
                
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç LLM: {response[:500]}...")
            return {"error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}", "raw_response": response[:500]}
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
            return {"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", "raw_response": response[:500] if response else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç"}
    
    def _is_error_response(self, response: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –æ—à–∏–±–∫—É API."""
        if not response:
            return True
        
        error_indicators = [
            "error code:",
            "error:",
            "insufficient_quota",
            "rate_limit_exceeded", 
            "invalid_api_key",
            "user location is not supported",
            "authentication failed",
            "permission denied",
            "service unavailable",
            "internal server error"
        ]
        
        response_lower = response.lower()
        return any(indicator in response_lower for indicator in error_indicators)
    
    def _extract_error_message(self, response: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞."""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON —Å –æ—à–∏–±–∫–æ–π
            import json
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                error_data = json.loads(json_match.group())
                if 'error' in error_data:
                    if isinstance(error_data['error'], dict):
                        return error_data['error'].get('message', str(error_data['error']))
                    else:
                        return str(error_data['error'])
            
            # –ï—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤
            return response[:200] + "..." if len(response) > 200 else response
            
        except:
            return response[:200] + "..." if len(response) > 200 else response
    
    def _clean_json_string(self, json_str: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É JSON –æ—Ç –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        # –£–¥–∞–ª—è–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        json_str = re.sub(r'```json\s*', '', json_str)
        json_str = re.sub(r'```\s*$', '', json_str)
        return json_str.strip()
    
    def _normalize_invoice_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–Ω–≤–æ–π—Å–∞."""
        normalized = {}
        
        for key, value in data.items():
            if value is None or value == "":
                continue
                
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è
            if any(word in key.lower() for word in ['—Å—É–º–º–∞', '–Ω–¥—Å', '–∏–Ω–Ω', '–∫–ø–ø', '–±–∏–∫']):
                if isinstance(value, str):
                    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–ø—è—Ç—ã–µ, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫–∏
                    cleaned_value = re.sub(r'[^\d,.]', '', value)
                    cleaned_value = cleaned_value.replace(',', '.')
                    try:
                        if '.' in cleaned_value:
                            normalized[key] = float(cleaned_value)
                        else:
                            normalized[key] = int(cleaned_value) if cleaned_value else 0
                    except ValueError:
                        normalized[key] = value
                else:
                    normalized[key] = value
            else:
                normalized[key] = value
                
        return normalized
    
    def _safe_float(self, value) -> float:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float."""
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            try:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, —Ç–æ—á–µ–∫ –∏ –∑–∞–ø—è—Ç—ã—Ö
                cleaned = re.sub(r'[^\d,.]', '', value)
                cleaned = cleaned.replace(',', '.')
                return float(cleaned) if cleaned else 0.0
            except ValueError:
                return 0.0
        return 0.0
    
    def get_model_info(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏."""
        return {
            "provider": self.provider_config.display_name,
            "model": self.model_name,
            "supports_vision": self.provider_config.supports_vision,
            "requires_api_key": self.provider_config.requires_api_key,
            "is_loaded": self.is_loaded
        }
    
    @staticmethod
    def get_available_providers() -> Dict[str, LLMProviderConfig]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ LLM."""
        return LLM_PROVIDERS
    
    @staticmethod
    def get_provider_models(provider_name: str) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        provider = LLM_PROVIDERS.get(provider_name)
        return provider.models if provider else []
    
    @staticmethod
    def update_provider_models(provider_name: str, models: List[str]) -> bool:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.
        
        Args:
            provider_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            models: –ù–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            
        Returns:
            bool: True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        if provider_name not in LLM_PROVIDERS:
            print(f"‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            LLM_PROVIDERS[provider_name].models = models
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è {provider_name}: {len(models)} –º–æ–¥–µ–ª–µ–π")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è {provider_name}: {e}")
            return False
    
    @staticmethod
    def refresh_provider_models(provider_name: str, api_key: str = None) -> List[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.
        
        Args:
            provider_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            api_key: API –∫–ª—é—á –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        if provider_name not in LLM_PROVIDERS:
            print(f"‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
            return []
        
        try:
            if provider_name == "openai":
                return BaseLLMPlugin._refresh_openai_models(api_key)
            elif provider_name == "google":
                return BaseLLMPlugin._refresh_google_models(api_key)
            elif provider_name == "anthropic":
                return BaseLLMPlugin._refresh_anthropic_models(api_key)
            else:
                print(f"‚ö†Ô∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {provider_name} –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                return LLM_PROVIDERS[provider_name].models
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è {provider_name}: {e}")
            return LLM_PROVIDERS[provider_name].models
    
    @staticmethod
    def _refresh_openai_models(api_key: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π OpenAI."""
        if not api_key:
            print("‚ùå API –∫–ª—é—á OpenAI –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            return LLM_PROVIDERS["openai"].models
        
        try:
            import openai
            client = openai.OpenAI(api_key=api_key)
            models_response = client.models.list()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ GPT –º–æ–¥–µ–ª–∏ –¥–ª—è chat completions
            chat_models = []
            for model in models_response.data:
                model_id = model.id
                if any(gpt_prefix in model_id for gpt_prefix in ["gpt-4", "gpt-3.5"]):
                    # –ò—Å–∫–ª—é—á–∞–µ–º embedding –∏ deprecated –º–æ–¥–µ–ª–∏
                    if "embedding" not in model_id and not BaseLLMPlugin._is_openai_model_deprecated(model_id):
                        chat_models.append(model_id)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
            chat_models.sort()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            if chat_models:
                BaseLLMPlugin.update_provider_models("openai", chat_models)
            
            return chat_models
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π OpenAI: {e}")
            return LLM_PROVIDERS["openai"].models
    
    @staticmethod
    def _refresh_google_models(api_key: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Google Gemini."""
        if not api_key:
            print("‚ùå API –∫–ª—é—á Google –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            return LLM_PROVIDERS["google"].models
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models_list = genai.list_models()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ Gemini –º–æ–¥–µ–ª–∏
            gemini_models = []
            for model in models_list:
                if "gemini" in model.name.lower() and "generateContent" in model.supported_generation_methods:
                    gemini_models.append(model.name)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
            gemini_models.sort()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            if gemini_models:
                BaseLLMPlugin.update_provider_models("google", gemini_models)
            
            return gemini_models
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π Google: {e}")
            return LLM_PROVIDERS["google"].models
    
    @staticmethod
    def _refresh_anthropic_models(api_key: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Anthropic (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫)."""
        # Anthropic –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        print("‚ÑπÔ∏è Anthropic –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π")
        return LLM_PROVIDERS["anthropic"].models
    
    @staticmethod
    def _is_openai_model_deprecated(model_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å OpenAI —É—Å—Ç–∞—Ä–µ–≤—à–µ–π."""
        deprecated_models = [
            "gpt-4-vision-preview",
            "gpt-4-0314",
            "gpt-4-32k-0314", 
            "gpt-3.5-turbo-0301",
            "text-davinci-003",
            "text-davinci-002",
            "code-davinci-002"
        ]
        return model_id in deprecated_models 