"""
LLM Trainer - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ –ø–ª–∞–≥–∏–Ω–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç LoRA/QLoRA –¥–ª—è Llama, CodeLlama, Mistral –∏ –¥—Ä—É–≥–∏—Ö LLM
"""

import os
import json
import torch
from typing import Dict, Any, Optional, List
from pathlib import Path
import logging

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å LoRA trainer
from app.training.core.base_lora_trainer import BaseLoraTrainer, ModelType

try:
    from transformers import (
        AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer,
        DataCollatorForLanguageModeling, BitsAndBytesConfig
    )
    from datasets import Dataset
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training
    LORA_AVAILABLE = True
except ImportError:
    LORA_AVAILABLE = False


class LLMTrainer(BaseLoraTrainer):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π LoRA/QLoRA
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - Llama 2/3 (llama)
    - Code Llama (codellama) 
    - Mistral (mistral)
    - –õ—é–±—ã–µ Causal LM –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, model_name: str, logger: Optional[logging.Logger] = None):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –∏–º–µ–Ω–∏
        model_type = self._detect_model_type(model_name)
        super().__init__(model_type, logger)
        
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.data_collator = None
        self.trainer = None
        
    def _detect_model_type(self, model_name: str) -> ModelType:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –∏–º–µ–Ω–∏"""
        model_name_lower = model_name.lower()
        
        if "llama" in model_name_lower and "code" in model_name_lower:
            return ModelType.CODELLAMA
        elif "llama" in model_name_lower:
            return ModelType.LLAMA
        elif "mistral" in model_name_lower:
            return ModelType.MISTRAL
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Llama –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            return ModelType.LLAMA
    
    def load_model_and_tokenizer(self, model_path: str, use_4bit: bool = True) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –∏–ª–∏ HuggingFace model ID
            use_4bit: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è QLoRA
        """
        if not TRANSFORMERS_AVAILABLE:
            self._log("‚ùå Transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", "error")
            return False
        
        try:
            self._log(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä {model_path}...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_path,
                trust_remote_code=True,
                cache_dir="data/models"
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º pad_token –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self._log("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ (QLoRA)
            quantization_config = None
            if use_4bit and LORA_AVAILABLE:
                quantization_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_use_double_quant=True,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_compute_dtype=torch.float16,
                )
                self._log("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è QLoRA")
            
            self._log(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_path}...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = AutoModelForCausalLM.from_pretrained(
                model_path,
                quantization_config=quantization_config,
                device_map="auto",
                trust_remote_code=True,
                torch_dtype=torch.float16,
                cache_dir="data/models"
            )
            
            self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –°–æ–∑–¥–∞–µ–º data collator
            self.data_collator = DataCollatorForLanguageModeling(
                tokenizer=self.tokenizer,
                mlm=False,  # –î–ª—è Causal LM
            )
            
            return True
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}", "error")
            return False
    
    def prepare_training_data(self, dataset_path: str, max_length: int = 512) -> Optional[Dataset]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            dataset_path: –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É (JSON/JSONL)
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        try:
            self._log(f"üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {dataset_path}...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            if dataset_path.endswith('.json'):
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        texts = data
                    else:
                        # –û–∂–∏–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç {"texts": [...]} –∏–ª–∏ {"data": [...]}
                        texts = data.get('texts', data.get('data', []))
            elif dataset_path.endswith('.jsonl'):
                texts = []
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        item = json.loads(line.strip())
                        texts.append(item.get('text', item.get('content', str(item))))
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {dataset_path}")
            
            self._log(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
            
            # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã
            def tokenize_function(examples):
                # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å padding –∏ truncation
                result = self.tokenizer(
                    examples['text'],
                    truncation=True,
                    padding='max_length',
                    max_length=max_length,
                    return_tensors=None
                )
                
                # –î–ª—è Causal LM labels = input_ids
                result['labels'] = result['input_ids'].copy()
                
                return result
            
            # –°–æ–∑–¥–∞–µ–º Dataset
            dataset = Dataset.from_dict({'text': texts})
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é
            tokenized_dataset = dataset.map(
                tokenize_function,
                batched=True,
                remove_columns=['text']
            )
            
            self._log(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {len(tokenized_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
            
            return tokenized_dataset
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}", "error")
            return None
    
    def train_llm(self, 
                  dataset: Dataset,
                  output_dir: str,
                  training_args: Dict[str, Any]) -> Optional[str]:
        """
        –û–±—É—á–∞–µ—Ç —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å —Å LoRA
        
        Args:
            dataset: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            training_args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        if not self.model or not self.tokenizer:
            self._log("‚ùå –ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω—ã", "error")
            return None
        
        try:
            self._log("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å LoRA...")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º LoRA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            if training_args.get('use_lora', True):
                self.model, lora_success = self.apply_lora_optimization(
                    self.model, training_args
                )
                if not lora_success:
                    self._log("‚ö†Ô∏è LoRA –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ", "warning")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥—Ä—É–≥–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
            self.model = self.apply_memory_optimizations(self.model, training_args)
            
            # –°–æ–∑–¥–∞–µ–º TrainingArguments
            training_arguments = TrainingArguments(
                output_dir=output_dir,
                num_train_epochs=training_args.get('num_epochs', 3),
                per_device_train_batch_size=training_args.get('batch_size', 4),
                gradient_accumulation_steps=training_args.get('gradient_accumulation_steps', 4),
                warmup_steps=training_args.get('warmup_steps', 100),
                max_steps=training_args.get('max_steps', -1),
                learning_rate=training_args.get('learning_rate', 2e-4),
                fp16=training_args.get('fp16', True),
                logging_steps=training_args.get('logging_steps', 10),
                save_steps=training_args.get('save_steps', 500),
                eval_steps=training_args.get('eval_steps', 500),
                save_total_limit=training_args.get('save_total_limit', 2),
                remove_unused_columns=False,
                dataloader_pin_memory=False,
                group_by_length=True,
                ddp_find_unused_parameters=False,
            )
            
            # –°–æ–∑–¥–∞–µ–º Trainer
            self.trainer = Trainer(
                model=self.model,
                args=training_arguments,
                train_dataset=dataset,
                data_collator=self.data_collator,
            )
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            self._log("üî• –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
            train_result = self.trainer.train()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self._log("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            self.trainer.save_model()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self._log(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            self._log(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π loss: {train_result.training_loss:.4f}")
            
            return output_dir
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}", "error")
            return None
    
    def _apply_model_specific_optimizations(self, model, training_args: Dict[str, Any]) -> Any:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è LLM –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        # –î–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        try:
            # Flash Attention (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if hasattr(model.config, 'use_flash_attention_2'):
                model.config.use_flash_attention_2 = True
                self._log("‚úÖ Flash Attention 2 –≤–∫–ª—é—á–µ–Ω")
        except Exception as e:
            self._log(f"‚ö†Ô∏è Flash Attention –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}", "warning")
        
        return model
    
    def evaluate_model(self, dataset: Dataset) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏"""
        if not self.trainer:
            self._log("‚ùå Trainer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", "error")
            return {}
        
        try:
            self._log("üìä –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å...")
            eval_results = self.trainer.evaluate(dataset)
            
            self._log(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
            for key, value in eval_results.items():
                self._log(f"   {key}: {value:.4f}")
            
            return eval_results
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏: {e}", "error")
            return {}
    
    def generate_text(self, prompt: str, max_length: int = 100) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self.model or not self.tokenizer:
            return "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
        
        try:
            inputs = self.tokenizer(prompt, return_tensors="pt")
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=max_length,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π prompt –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if generated_text.startswith(prompt):
                generated_text = generated_text[len(prompt):].strip()
            
            return generated_text
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}" 