"""
–ü–ª–∞–≥–∏–Ω –¥–ª—è OpenAI API (ChatGPT, GPT-4 Vision).
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ OpenAI —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
"""
import os
import json
import base64
from datetime import datetime
from typing import Dict, Optional, Any
from pathlib import Path
from PIL import Image

from ..base_llm_plugin import BaseLLMPlugin

class OpenAIPlugin(BaseLLMPlugin):
    """
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–≥–∏–Ω –¥–ª—è OpenAI API.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç ChatGPT –∏ GPT-4 Vision –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    """
    
    def __init__(self, model_name: str = None, api_key: str = None, **kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–∞ OpenAI.
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ OpenAI
            api_key: API –∫–ª—é—á OpenAI
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        super().__init__("openai", model_name, api_key, **kwargs)
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è OpenAI
        self.max_image_size = kwargs.get('max_image_size', 20 * 1024 * 1024)  # 20MB
        self.image_quality = kwargs.get('image_quality', 'high')  # high, low, auto
        
        print(f"ü§ñ –°–æ–∑–¥–∞–Ω –ø–ª–∞–≥–∏–Ω OpenAI –¥–ª—è –º–æ–¥–µ–ª–∏ {self.model_name}")
    
    def load_model(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç OpenAI.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        try:
            import openai
            
            if not self.api_key:
                print("‚ùå API –∫–ª—é—á OpenAI –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
                return False
            
            self.client = openai.OpenAI(api_key=self.api_key)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
            try:
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=1
                )
                
                self.is_loaded = True
                print(f"‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {self.model_name}")
                return True
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API: {e}")
                return False
                
        except ImportError:
            print("‚ùå –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
            return False
    
    def _encode_image_base64(self, image_path: str) -> str:
        """
        –ö–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            
        Returns:
            str: Base64 —Å—Ç—Ä–æ–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        try:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ
            image = Image.open(image_path)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # –°–∂–∏–º–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ
            max_size = (2048, 2048)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è GPT-4 Vision
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
                print(f"üìè –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∂–∞—Ç–æ –¥–æ {image.size}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                image.save(temp_file.name, 'JPEG', quality=85)
                temp_path = temp_file.name
            
            try:
                with open(temp_path, "rb") as image_file:
                    encoded = base64.b64encode(image_file.read()).decode('utf-8')
                return encoded
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            raise
    
    def generate_response(self, prompt: str, image_path: str = None, image_context: str = "") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç OpenAI.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
            image_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            str: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        if not self.is_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—å OpenAI –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        try:
            messages = []
            
            if image_path and os.path.exists(image_path):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                vision_models = ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4-vision-preview"]
                if not any(vm in self.model_name for vm in vision_models):
                    return f"–ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
                
                # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                base64_image = self._encode_image_base64(image_path)
                
                messages.append({
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": self.image_quality
                            }
                        }
                    ]
                })
            else:
                # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                messages.append({
                    "role": "user",
                    "content": prompt
                })
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=self.generation_config.get("max_tokens", 4096),
                temperature=self.generation_config.get("temperature", 0.1),
                top_p=self.generation_config.get("top_p", 0.9)
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ OpenAI: {e}")
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    def process_image(self, image_path: str, ocr_lang=None, custom_prompt=None) -> Optional[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–Ω–≤–æ–π—Å–∞.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            ocr_lang: –Ø–∑—ã–∫ OCR (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–µ)
            custom_prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            
        Returns:
            Optional[Dict]: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        if not self.is_loaded:
            print("‚ùå –ú–æ–¥–µ–ª—å OpenAI –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π
            if custom_prompt:
                prompt = custom_prompt
            else:
                prompt = self.create_invoice_prompt(custom_prompt, True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —è–∑—ã–∫–µ, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if ocr_lang:
                lang_info = f"\n–Ø–∑—ã–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {ocr_lang}"
                prompt += lang_info
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.generate_response(prompt, image_path)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                json_match = None
                if '```json' in response:
                    json_start = response.find('```json') + 7
                    json_end = response.find('```', json_start)
                    json_match = response[json_start:json_end].strip()
                elif '{' in response and '}' in response:
                    json_start = response.find('{')
                    json_end = response.rfind('}') + 1
                    json_match = response[json_start:json_end]
                
                if json_match:
                    result = json.loads(json_match)
                    return self._normalize_invoice_data(result)
                else:
                    print("‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
                    return None
                    
            except json.JSONDecodeError as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                print(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None
    
    def extract_invoice_data(self, image_path: str, prompt: str = None) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏–Ω–≤–æ–π—Å–∞.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–Ω–≤–æ–π—Å–∞
            prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            
        Returns:
            Dict[str, Any]: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        if not self.is_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        result = self.process_image(image_path, custom_prompt=prompt)
        return result if result else {}
    
    def get_model_info(self) -> dict:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏.
        
        Returns:
            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        """
        info = super().get_model_info()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö OpenAI
        model_specs = {
            "gpt-4o": {
                "max_tokens": 4096,
                "context_window": 128000,
                "supports_vision": True,
                "input_cost_per_1k": 0.005,
                "output_cost_per_1k": 0.015
            },
            "gpt-4o-mini": {
                "max_tokens": 16384,
                "context_window": 128000,
                "supports_vision": True,
                "input_cost_per_1k": 0.00015,
                "output_cost_per_1k": 0.0006
            },
            "gpt-4-turbo": {
                "max_tokens": 4096,
                "context_window": 128000,
                "supports_vision": True,
                "input_cost_per_1k": 0.01,
                "output_cost_per_1k": 0.03
            },
            "gpt-3.5-turbo": {
                "max_tokens": 4096,
                "context_window": 16385,
                "supports_vision": False,
                "input_cost_per_1k": 0.0015,
                "output_cost_per_1k": 0.002
            }
        }
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
        spec = None
        for model_key, model_spec in model_specs.items():
            if model_key in self.model_name:
                spec = model_spec
                break
        
        if spec:
            info.update(spec)
        
        info.update({
            "provider": "OpenAI",
            "supports_pdf": False,  # –¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            "image_quality": self.image_quality,
            "max_image_size": self.max_image_size
        })
        
        return info
    
    def cleanup(self):
        """–û—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã –ø–ª–∞–≥–∏–Ω–∞."""
        self.is_loaded = False
        self.client = None
        print("üßπ –†–µ—Å—É—Ä—Å—ã –ø–ª–∞–≥–∏–Ω–∞ OpenAI –æ—á–∏—â–µ–Ω—ã")
    
    def __del__(self):
        """–î–µ—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        try:
            self.cleanup()
        except:
            pass 