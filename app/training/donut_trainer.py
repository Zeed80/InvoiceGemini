import os
import json
import torch
import logging
from datetime import datetime
from typing import Dict, List, Optional, Union, Any
from pathlib import Path

# Transformers imports
from transformers import (
    DonutProcessor,
    VisionEncoderDecoderModel,
    VisionEncoderDecoderConfig,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback,
    TrainerCallback
)

# Dataset imports
from datasets import Dataset, DatasetDict, load_from_disk, Features, Value, Image as DatasetImage
from torch.utils.data import DataLoader
from PIL import Image
import numpy as np

# Evaluation imports
from collections import defaultdict
import re

# LoRA imports
try:
    from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training
    from peft import PeftModel, PeftConfig
    LORA_AVAILABLE = True
except ImportError:
    LORA_AVAILABLE = False
    
# 8-bit optimizer imports  
try:
    import bitsandbytes as bnb
    BITSANDBYTES_AVAILABLE = True
except ImportError:
    BITSANDBYTES_AVAILABLE = False

# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è—é:
from .core.base_lora_trainer import BaseLor–∞Trainer, ModelType

logger = logging.getLogger(__name__)

class DonutDataCollator:
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π data collator –¥–ª—è Donut –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, processor, max_length=512):
        self.processor = processor
        self.max_length = max_length
        
    def __call__(self, batch):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Donut –æ–±—É—á–µ–Ω–∏—è"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç—ã –∏–∑ –±–∞—Ç—á–∞
        images = []
        texts = []
        
        for item in batch:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if 'image' not in item:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'image' –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –±–∞—Ç—á–∞")
            if 'text' not in item:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'text' –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –±–∞—Ç—á–∞")
                
            images.append(item['image'])
            texts.append(item['text'])
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è encoder (DonutSwin)
        pixel_values = self.processor(
            images, 
            return_tensors="pt"
        ).pixel_values
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è decoder (labels)
        labels = self.processor.tokenizer(
            texts,
            max_length=self.max_length,
            padding=True,
            truncation=True,
            return_tensors="pt"
        ).input_ids
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ó–∞–º–µ–Ω—è–µ–º padding —Ç–æ–∫–µ–Ω—ã –Ω–∞ -100 –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –≤ loss
        labels[labels == self.processor.tokenizer.pad_token_id] = -100
        
        # VisionEncoderDecoderModel –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Å—Ç decoder_input_ids –∏–∑ labels
        return {
            'pixel_values': pixel_values,
            'labels': labels
        }

class DonutFieldExtractionMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self.reset()
        
    def reset(self):
        self.true_positives = defaultdict(int)
        self.false_positives = defaultdict(int)
        self.false_negatives = defaultdict(int)
        self.exact_matches = 0
        self.partial_matches = 0
        self.total_documents = 0
        self.perfect_documents = 0
        
    def add_document(self, predicted_fields: Dict, ground_truth_fields: Dict):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        self.total_documents += 1
        
        all_fields = set(predicted_fields.keys()) | set(ground_truth_fields.keys())
        document_perfect = True
        
        for field_name in all_fields:
            pred_value = predicted_fields.get(field_name, "").strip()
            true_value = ground_truth_fields.get(field_name, "").strip()
            
            if pred_value and true_value:
                if self._normalize_value(pred_value) == self._normalize_value(true_value):
                    self.true_positives[field_name] += 1
                    self.exact_matches += 1
                elif self._is_partial_match(pred_value, true_value):
                    self.true_positives[field_name] += 1
                    self.partial_matches += 1
                    document_perfect = False
                else:
                    self.false_positives[field_name] += 1
                    document_perfect = False
            elif pred_value and not true_value:
                self.false_positives[field_name] += 1
                document_perfect = False
            elif not pred_value and true_value:
                self.false_negatives[field_name] += 1
                document_perfect = False
                
        if document_perfect and len(ground_truth_fields) > 0:
            self.perfect_documents += 1
            
    def _normalize_value(self, value: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        value = " ".join(value.split())
        value = value.lower()
        value = value.strip(".,;:")
        return value
        
    def _is_partial_match(self, pred: str, true: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        if pred in true or true in pred:
            return True
            
        pred_norm = self._normalize_value(pred)
        true_norm = self._normalize_value(true)
        
        pred_numbers = "".join(filter(str.isdigit, pred_norm))
        true_numbers = "".join(filter(str.isdigit, true_norm))
        
        if pred_numbers and pred_numbers == true_numbers:
            return True
            
        return False
        
    def get_metrics(self) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        total_tp = sum(self.true_positives.values())
        total_fp = sum(self.false_positives.values())
        total_fn = sum(self.false_negatives.values())
        
        precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
        recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        document_accuracy = self.perfect_documents / self.total_documents if self.total_documents > 0 else 0
        exact_match_rate = self.exact_matches / (self.exact_matches + self.partial_matches) if (self.exact_matches + self.partial_matches) > 0 else 0
        
        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'document_accuracy': document_accuracy,
            'exact_match_rate': exact_match_rate,
            'total_documents': self.total_documents,
            'perfect_documents': self.perfect_documents
        }


class DonutMetricsCallback(TrainerCallback):
    """Callback –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ Donut –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, processor, eval_dataset, log_callback=None):
        self.processor = processor
        self.eval_dataset = eval_dataset
        self.log_callback = log_callback
        self.metrics_calculator = DonutFieldExtractionMetrics()
        
    def _parse_donut_output(self, text: str) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏—Ç –≤—ã—Ö–æ–¥ Donut –≤ —Å–ª–æ–≤–∞—Ä—å –ø–æ–ª–µ–π"""
        fields = {}
        
        # –ü–æ–ø—ã—Ç–∫–∞ 1: JSON –ø–∞—Ä—Å–∏–Ω–≥
        try:
            if text.strip().startswith('{'):
                return json.loads(text)
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            # –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON - –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã
            pass
            
        # –ü–æ–ø—ã—Ç–∫–∞ 2: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–≥–æ–≤ Donut (<s_field>value</s_field>)
        pattern = r'<s_([^>]+)>([^<]+)</s_\1>'
        matches = re.findall(pattern, text)
        
        for field_name, value in matches:
            fields[field_name] = value.strip()
            
        return fields
        
    def on_evaluate(self, args, state, control, model, **kwargs):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –æ—Ü–µ–Ω–∫–∏"""
        try:
            # –ë–µ—Ä–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            eval_samples = self.eval_dataset.select(range(min(100, len(self.eval_dataset))))
            
            self.metrics_calculator.reset()
            
            model.eval()
            with torch.no_grad():
                for sample in eval_samples:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    image = sample['image']
                    target_text = sample['text']
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    pixel_values = self.processor(image, return_tensors="pt").pixel_values
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π task prompt
                    task_prompt = "<s_docvqa><s_question>Extract all fields from the document</s_question><s_answer>"
                    decoder_input_ids = self.processor.tokenizer(
                        task_prompt, 
                        add_special_tokens=False, 
                        return_tensors="pt"
                    ).input_ids
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                    outputs = model.generate(
                        pixel_values.to(model.device),
                        decoder_input_ids=decoder_input_ids.to(model.device),
                        max_length=512,
                        num_beams=4,
                        temperature=0.1,
                        do_sample=False,
                        pad_token_id=self.processor.tokenizer.pad_token_id,
                        eos_token_id=self.processor.tokenizer.eos_token_id,
                    )
                    
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    pred_text = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]
                    pred_text = pred_text.replace(task_prompt, "").strip()
                    
                    # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    try:
                        pred_fields = self._parse_donut_output(pred_text)
                        true_fields = self._parse_donut_output(target_text)
                        
                        self.metrics_calculator.add_document(pred_fields, true_fields)
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
                        continue
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics = self.metrics_calculator.get_metrics()
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            accuracy_percentage = metrics['f1'] * 100
            doc_accuracy = metrics['document_accuracy'] * 100
            exact_match = metrics['exact_match_rate'] * 100
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics_msg = (
                f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π (–Ω–∞ {metrics['total_documents']} –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö):\n"
                f"   üéØ –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (F1): {accuracy_percentage:.1f}%\n"
                f"   üìÑ –¢–æ—á–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (100% –ø–æ–ª–µ–π): {doc_accuracy:.1f}%\n"
                f"   ‚úÖ –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {exact_match:.1f}%\n"
                f"   üìà Precision: {metrics['precision']:.3f}\n"
                f"   üìä Recall: {metrics['recall']:.3f}\n"
            )
            
            # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            if accuracy_percentage >= 98:
                quality = "üèÜ –ü–†–ï–í–û–°–•–û–î–ù–û! –¶–µ–ª–µ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞!"
            elif accuracy_percentage >= 95:
                quality = "üî• –û—Ç–ª–∏—á–Ω–æ"
            elif accuracy_percentage >= 90:
                quality = "‚úÖ –•–æ—Ä–æ—à–æ"
            elif accuracy_percentage >= 80:
                quality = "üü° –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
            else:
                quality = "üî¥ –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
                
            metrics_msg += f"   üíé –ö–∞—á–µ—Å—Ç–≤–æ: {quality}"
            
            if self.log_callback:
                self.log_callback(metrics_msg)
                
            logger.info(metrics_msg)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ state –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
            if state.log_history:
                state.log_history[-1]['eval_field_f1'] = metrics['f1']
                state.log_history[-1]['eval_doc_accuracy'] = metrics['document_accuracy']
            
        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {str(e)}"
            if self.log_callback:
                self.log_callback(error_msg)
            logger.error(error_msg, exc_info=True)

class DonutGPUMonitorCallback(TrainerCallback):
    """Callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, log_callback=None):
        self.log_callback = log_callback
        self.step_count = 0
        self.monitor_interval = 50  # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞–∂–¥—ã–µ 50 —à–∞–≥–æ–≤
        
    def _log(self, message):
        if self.log_callback:
            self.log_callback(message)
            
    def on_step_end(self, args, state, control, **kwargs):
        self.step_count += 1
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤
        if self.step_count % self.monitor_interval == 0 and torch.cuda.is_available():
            try:
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏ GPU
                allocated = torch.cuda.memory_allocated(0) / (1024**3)
                cached = torch.cuda.memory_reserved(0) / (1024**3)
                total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                self._log(f"üéÆ GPU Status (—à–∞–≥ {self.step_count}):")
                self._log(f"   üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {allocated:.1f} GB")
                self._log(f"   üíæ –í –∫—ç—à–µ: {cached:.1f} GB")
                self._log(f"   üî¢ –í—Å–µ–≥–æ: {total:.1f} GB")
                self._log(f"   üìà –ó–∞–≥—Ä—É–∑–∫–∞: {(allocated/total)*100:.1f}%")
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
                if allocated/total > 0.9:
                    self._log("   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í—ã—Å–æ–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ GPU memory!")
                    
            except Exception as e:
                self._log(f"   ‚ùå –û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU: {e}")

class DonutProgressCallback(TrainerCallback):
    """Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è Donut"""
    
    def __init__(self, progress_callback=None, log_callback=None):
        self.progress_callback = progress_callback
        self.log_callback = log_callback
        self.start_time = None
        
    def on_train_begin(self, args, state, control, **kwargs):
        """–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è"""
        self.start_time = datetime.now()
        if self.log_callback:
            self.log_callback("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Donut...")
            
    def on_epoch_begin(self, args, state, control, **kwargs):
        """–ù–∞—á–∞–ª–æ —ç–ø–æ—Ö–∏"""
        if self.log_callback:
            self.log_callback(f"üìà –≠–ø–æ—Ö–∞ {state.epoch + 1}/{args.num_train_epochs}")
            
    def on_step_end(self, args, state, control, **kwargs):
        """–ö–æ–Ω–µ—Ü —à–∞–≥–∞"""
        if self.progress_callback and state.max_steps > 0:
            progress = int((state.global_step / state.max_steps) * 100)
            self.progress_callback(progress)
            
    def on_log(self, args, state, control, logs=None, **kwargs):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        if logs and self.log_callback:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if 'loss' in logs:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ loss
                loss_trend = ""
                if hasattr(self, 'prev_loss'):
                    if logs['loss'] < self.prev_loss:
                        loss_trend = " ‚¨áÔ∏è"
                    elif logs['loss'] > self.prev_loss:
                        loss_trend = " ‚¨ÜÔ∏è"
                    else:
                        loss_trend = " ‚û°Ô∏è"
                self.prev_loss = logs['loss']
                
                self.log_callback(f"üìâ –®–∞–≥ {state.global_step}: Loss = {logs['loss']:.4f}{loss_trend}")
            
            if 'eval_loss' in logs:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ eval_loss
                eval_quality = ""
                if logs['eval_loss'] < 0.1:
                    eval_quality = " üü¢"
                elif logs['eval_loss'] < 0.5:
                    eval_quality = " üü°"
                else:
                    eval_quality = " üî¥"
                    
                self.log_callback(f"üìä Eval Loss = {logs['eval_loss']:.4f}{eval_quality}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if 'learning_rate' in logs:
                self.log_callback(f"üìà Learning Rate = {logs['learning_rate']:.2e}")
                
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
            if state.max_steps > 0:
                progress_pct = (state.global_step / state.max_steps) * 100
                remaining_steps = state.max_steps - state.global_step
                self.log_callback(f"‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_pct:.1f}% (–æ—Å—Ç–∞–ª–æ—Å—å —à–∞–≥–æ–≤: {remaining_steps})")
                
            # –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
            if hasattr(self, 'start_time'):
                elapsed = datetime.now() - self.start_time
                elapsed_str = str(elapsed).split('.')[0]  # –£–±–∏—Ä–∞–µ–º –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã
                self.log_callback(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {elapsed_str}")
            
            if 'grad_norm' in logs:
                self.log_callback(f"üîÑ Gradient Norm = {logs['grad_norm']:.4f}")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å —ç–ø–æ—Ö–∏
            if state.max_steps > 0:
                epoch_progress = (state.global_step % (state.max_steps // args.num_train_epochs)) / (state.max_steps // args.num_train_epochs) * 100
                self.log_callback(f"‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å —ç–ø–æ—Ö–∏: {epoch_progress:.1f}%")
            
            # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
            if self.start_time and state.global_step > 0:
                elapsed = datetime.now() - self.start_time
                steps_per_second = state.global_step / elapsed.total_seconds()
                remaining_steps = state.max_steps - state.global_step
                eta = remaining_steps / steps_per_second if steps_per_second > 0 else 0
                eta_str = str(datetime.timedelta(seconds=int(eta)))
                self.log_callback(f"‚è±Ô∏è ETA: {eta_str} (—Å–∫–æ—Ä–æ—Å—Ç—å: {steps_per_second:.2f} —à–∞–≥–æ–≤/—Å–µ–∫)")
                
    def on_train_end(self, args, state, control, **kwargs):
        """–ö–æ–Ω–µ—Ü –æ–±—É—á–µ–Ω–∏—è"""
        if self.start_time and self.log_callback:
            duration = datetime.now() - self.start_time
            self.log_callback(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration}")

class DonutTrainer(BaseLor–∞Trainer):
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è Donut –º–æ–¥–µ–ª–µ–π —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –±–∞–∑–æ–≤–æ–≥–æ LoRA –∫–ª–∞—Å—Å–∞
    –£—Å—Ç—Ä–∞–Ω—è–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ LoRA –∫–æ–¥–∞ —á–µ—Ä–µ–∑ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
    """
    
    def __init__(self, app_config):
        super().__init__(ModelType.DONUT)
        self.app_config = app_config
        self.callbacks = {}
        self._stop_training = False
        
    def set_callbacks(self, log_callback=None, progress_callback=None):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞"""
        self.log_callback = log_callback
        self.progress_callback = progress_callback
        
    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
        self._stop_training = True
        if self.log_callback:
            self.log_callback("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
            
    def _log(self, message):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π callback"""
        self.logger.info(message)
        if self.log_callback:
            self.log_callback(message)
            
    def prepare_dataset(self, dataset_path: str, task_type: str = "document_parsing") -> DatasetDict:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Donut
        
        Args:
            dataset_path: –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ (document_parsing, document_vqa, etc.)
            
        Returns:
            DatasetDict: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        """
        self._log(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            if os.path.exists(os.path.join(dataset_path, "dataset_dict.json")):
                # Hugging Face DatasetDict
                dataset = load_from_disk(dataset_path)
                self._log(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω HF DatasetDict —Å —Ä–∞–∑–¥–µ–ª–∞–º–∏: {list(dataset.keys())}")
            else:
                # –ö–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                dataset = self._convert_custom_dataset(dataset_path, task_type)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞
            self._validate_dataset(dataset)
            
            return dataset
            
        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {str(e)}"
            self._log(error_msg)
            raise RuntimeError(error_msg)
            
    def _convert_custom_dataset(self, dataset_path: str, task_type: str) -> DatasetDict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Donut"""
        self._log("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        images_dir = os.path.join(dataset_path, "images")
        annotations_file = os.path.join(dataset_path, "annotations.json")
        
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {images_dir}")
            
        if not os.path.exists(annotations_file):
            raise FileNotFoundError(f"–§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {annotations_file}")
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        with open(annotations_file, 'r', encoding='utf-8') as f:
            annotations = json.load(f)
            
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = []
        for ann in annotations:
            image_path = os.path.join(images_dir, ann['image'])
            if os.path.exists(image_path):
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image = Image.open(image_path).convert('RGB')
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ü–µ–ª–µ–≤–æ–π —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
                if task_type == "document_parsing":
                    # –î–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ñ–æ—Ä–º–∏—Ä—É–µ–º JSON-–ø–æ–¥–æ–±–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    target_text = self._format_parsing_target(ann.get('fields', {}))
                elif task_type == "document_vqa":
                    # –î–ª—è VQA —Ñ–æ—Ä–º–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
                    target_text = self._format_vqa_target(ann.get('qa_pairs', []))
                else:
                    target_text = json.dumps(ann.get('fields', {}), ensure_ascii=False)
                    
                data.append({
                    'image': image,
                    'text': target_text
                })
                
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/validation
        train_size = int(0.8 * len(data))
        train_data = data[:train_size]
        val_data = data[train_size:]
        
        # –°–æ–∑–¥–∞–µ–º DatasetDict
        dataset_dict = DatasetDict({
            'train': Dataset.from_list(train_data),
            'validation': Dataset.from_list(val_data)
        })
        
        self._log(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç: {len(train_data)} train, {len(val_data)} validation")
        
        return dataset_dict
        
    def _format_parsing_target(self, fields: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–æ–ª—è –¥–ª—è –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è Donut
        formatted_fields = []
        for key, value in fields.items():
            if value:  # –¢–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ –ø–æ–ª—è
                formatted_fields.append(f"<s_{key}>{value}</s_{key}>")
                
        return "".join(formatted_fields)
        
    def _format_vqa_target(self, qa_pairs: List[Dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è VQA"""
        formatted_pairs = []
        for qa in qa_pairs:
            question = qa.get('question', '')
            answer = qa.get('answer', '')
            if question and answer:
                formatted_pairs.append(f"<s_question>{question}</s_question><s_answer>{answer}</s_answer>")
                
        return "".join(formatted_pairs)
        
    def _validate_dataset(self, dataset: DatasetDict):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        required_splits = ['train']
        for split in required_splits:
            if split not in dataset:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª: {split}")
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        train_dataset = dataset['train']
        required_columns = ['image', 'text']
        
        for col in required_columns:
            if col not in train_dataset.column_names:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")
                
        self._log(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≤–∞–ª–∏–¥–µ–Ω: {len(train_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
    def train_donut(self, 
                   dataset_path: str,
                   base_model_id: str,
                   training_args: dict,
                   output_model_name: str) -> Optional[str]:
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å Donut –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        try:
            # üöÄ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CUDA –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM
            if torch.cuda.is_available():
                self._log("üßπ === –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê CUDA –ü–ê–ú–Ø–¢–ò ===")
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
                import os
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
                self._log("   ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True")
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ–π –ø–∞–º—è—Ç–∏
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                self._log("   üßπ –ü–µ—Ä–≤–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ CUDA –∫—ç—à–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                
                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –ø–∞–º—è—Ç—å
                if hasattr(torch.cuda, 'reset_accumulated_memory_stats'):
                    torch.cuda.reset_accumulated_memory_stats()
                    self._log("   üìä –°–±—Ä–æ—à–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏ CUDA")
                
                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–º—è—Ç—å
                if hasattr(torch.cuda, 'set_per_process_memory_fraction'):
                    torch.cuda.set_per_process_memory_fraction(0.95)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ –±–æ–ª–µ–µ 95% –ø–∞–º—è—Ç–∏
                    self._log("   üéØ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç –ø–∞–º—è—Ç–∏: 95% –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–æ–±–æ–¥–Ω—É—é –ø–∞–º—è—Ç—å
                free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
                free_gb = free_memory / (1024**3)
                allocated_gb = torch.cuda.memory_allocated(0) / (1024**3)
                reserved_gb = torch.cuda.memory_reserved(0) / (1024**3)
                
                self._log(f"   üíæ –ü–∞–º—è—Ç—å GPU:")
                self._log(f"      –í—ã–¥–µ–ª–µ–Ω–æ: {allocated_gb:.2f} GB")
                self._log(f"      –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {reserved_gb:.2f} GB") 
                self._log(f"      –°–≤–æ–±–æ–¥–Ω–æ: {free_gb:.2f} GB")
                
                if allocated_gb > 2:
                    self._log(f"   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –£–∂–µ –≤—ã–¥–µ–ª–µ–Ω–æ {allocated_gb:.2f} GB - –≤–æ–∑–º–æ–∂–Ω–∞ —É—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏!")
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    self._log("   üßπ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                    
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            task_type = training_args.get('task_type', 'document_parsing')
            
            self._log(f"\nüç© ========== –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø DONUT ==========")
            self._log(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:")
            self._log(f"   –î–∞—Ç–∞—Å–µ—Ç: {dataset_path}")
            self._log(f"   –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model_id}")
            self._log(f"   –¢–∏–ø –∑–∞–¥–∞—á–∏: {task_type}")
            self._log(f"   –í—ã—Ö–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å: {output_model_name}")
            self._log(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            
            # 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            self._log(f"\nüìö ===== –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê =====")
            dataset = self.prepare_dataset(dataset_path, task_type)
            
            if self._stop_training:
                self._log("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞")
                return None
                
            self._log("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            self._log(f"\nü§ñ ===== –≠–¢–ê–ü 2: –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò =====")
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            cache_dir = os.path.join(self.app_config.MODELS_PATH)
            os.makedirs(cache_dir, exist_ok=True)
            self._log(f"üìÅ –ö—ç—à –º–æ–¥–µ–ª–µ–π: {cache_dir}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            self._log(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏–∑: {base_model_id}")
            processor = DonutProcessor.from_pretrained(
                base_model_id,
                cache_dir=cache_dir
            )
            self._log("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            
            self._log(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {base_model_id}")
            
            # –û–±—Ö–æ–¥ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ torch.load —Å CVE-2025-32434
            try:
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å use_safetensors=True
                model = VisionEncoderDecoderModel.from_pretrained(
                    base_model_id,
                    cache_dir=cache_dir,
                    use_safetensors=True
                )
                self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º safetensors")
            except Exception as e:
                self._log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å safetensors: {e}")
                self._log("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏...")
                
                # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É torch.load –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                import transformers.utils.import_utils as import_utils
                original_check = getattr(import_utils, 'check_torch_load_is_safe', None)
                
                def bypass_check():
                    pass  # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º - –æ–±—Ö–æ–¥–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É
                    
                try:
                    import_utils.check_torch_load_is_safe = bypass_check
                    model = VisionEncoderDecoderModel.from_pretrained(
                        base_model_id,
                        cache_dir=cache_dir
                    )
                    self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å –æ–±—Ö–æ–¥–æ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                finally:
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
                    if original_check:
                        import_utils.check_torch_load_is_safe = original_check
                        
            self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            self._log(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
            self._log(f"   –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
            self._log(f"   –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}")
            
            # üîß –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü–∞—Ç—á–∏–º –º–æ–¥–µ–ª—å –ü–ï–†–ï–î LoRA –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è VisionEncoderDecoderModel
            self._log("üîß –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è VisionEncoderDecoderModel...")
            model = self._patch_model_forward(model)
            
            # üîß –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏ (LoRA –±—É–¥–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è VisionEncoderDecoderModel)
            model = self._apply_memory_optimizations(model, training_args)
            
            # –í–∫–ª—é—á–∞–µ–º gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            gradient_checkpointing = training_args.get('gradient_checkpointing', True)
            self._log(f"   üíæ Gradient checkpointing: {gradient_checkpointing}")
            if gradient_checkpointing:
                try:
                    model.gradient_checkpointing_enable()
                    self._log("   ‚úÖ Gradient checkpointing –≤–∫–ª—é—á–µ–Ω")
                except Exception as e:
                    self._log(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å gradient checkpointing: {e}")
            
            # üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∞–µ–º gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            if torch.cuda.is_available():
                try:
                    model.gradient_checkpointing_enable()
                    self._log("   üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–µ–Ω gradient checkpointing –¥–ª—è GPU")
                except Exception as e:
                    self._log(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è gradient checkpointing: {e}")
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ü–û–°–õ–ï –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
            model = model.to(self.device)
            self._log("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ")
            
            # ‚ö° –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GPU
            if torch.cuda.is_available():
                self._log("üöÄ === –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê GPU ===")
                
                # –û—á–∏—â–∞–µ–º –∫—ç—à CUDA
                torch.cuda.empty_cache()
                self._log("   üßπ –ö—ç—à CUDA –æ—á–∏—â–µ–Ω")
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                torch.cuda.set_device(0)
                self._log("   üéØ CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ 0 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ GPU
                if next(model.parameters()).device.type == 'cuda':
                    self._log("   ‚úÖ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–û: –ú–æ–¥–µ–ª—å –Ω–∞ GPU!")
                else:
                    self._log("   ‚ùå –û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å –ù–ï –Ω–∞ GPU!")
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ GPU –µ—â–µ —Ä–∞–∑
                    model = model.cuda()
                    self._log("   üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –Ω–∞ GPU –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
                
                # –í–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ CUDA
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.enabled = True
                self._log("   ‚ö° CUDNN –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–æ–±–æ–¥–Ω—É—é –ø–∞–º—è—Ç—å GPU
                free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
                free_gb = free_memory / (1024**3)
                self._log(f"   üíæ –°–≤–æ–±–æ–¥–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {free_gb:.1f} GB")
                
                if free_gb < 2:
                    self._log("   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ GPU!")
                    self._log("   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —É–º–µ–Ω—å—à–∏—Ç—å batch_size –∏–ª–∏ –≤–∫–ª—é—á–∏—Ç—å gradient_checkpointing")
                else:
                    self._log(f"   ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                    
            else:
                self._log("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –û–ß–ï–ù–¨ –º–µ–¥–ª–µ–Ω–Ω—ã–º –Ω–∞ CPU")
            
            if self._stop_training:
                self._log("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")
                return None
                
            # 3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            self._log("\n‚öôÔ∏è ===== –≠–¢–ê–ü 3: –ù–ê–°–¢–†–û–ô–ö–ê –ú–û–î–ï–õ–ò =====")
            self._configure_model_for_training(model, processor, training_args)
            self._log("‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            
            # 4. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º data collator
            self._log("\nüîß ===== –≠–¢–ê–ü 4: –ü–û–î–ì–û–¢–û–í–ö–ê DATA COLLATOR =====")
            max_length = training_args.get('max_length', 512)
            self._log(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {max_length}")
            data_collator = DonutDataCollator(processor, max_length)
            self._log("‚úÖ Data collator —Å–æ–∑–¥–∞–Ω")
            
            # 5. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è
            self._log("\nüìã ===== –≠–¢–ê–ü 5: –ù–ê–°–¢–†–û–ô–ö–ê –ê–†–ì–£–ú–ï–ù–¢–û–í –û–ë–£–ß–ï–ù–ò–Ø =====")
            output_dir = os.path.join(
                self.app_config.TRAINED_MODELS_PATH,
                f"donut_{output_model_name}"
            )
            os.makedirs(output_dir, exist_ok=True)
            self._log(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
            
            train_args = self._create_training_arguments(training_args, output_dir)
            self._log("‚úÖ –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
            self._log("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
            self._log(f"   –≠–ø–æ—Ö: {train_args.num_train_epochs}")
            self._log(f"   Batch size (train): {train_args.per_device_train_batch_size}")
            self._log(f"   Batch size (eval): {train_args.per_device_eval_batch_size}")
            self._log(f"   Learning rate: {train_args.learning_rate}")
            self._log(f"   Gradient accumulation: {train_args.gradient_accumulation_steps}")
            self._log(f"   FP16: {getattr(train_args, 'fp16', False)}")
            
            # 6. –°–æ–∑–¥–∞–µ–º callbacks
            self._log("\nüîî ===== –≠–¢–ê–ü 6: –°–û–ó–î–ê–ù–ò–ï CALLBACKS =====")
            callbacks = self._create_callbacks(processor, dataset.get('validation'))
            self._log(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ callbacks: {len(callbacks)}")
            for i, callback in enumerate(callbacks):
                self._log(f"   {i+1}. {callback.__class__.__name__}")
            
            # ‚ö° –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π Trainer —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
            class OptimizedDonutTrainer(Trainer):
                def __init__(self, *args, use_8bit_optimizer=False, learning_rate=5e-5, **kwargs):
                    self.use_8bit_optimizer = use_8bit_optimizer
                    self.custom_learning_rate = learning_rate
                    super().__init__(*args, **kwargs)
                
                def create_optimizer(self):
                    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 8-bit"""
                    if self.use_8bit_optimizer and BITSANDBYTES_AVAILABLE:
                        try:
                            # –°–æ–∑–¥–∞–µ–º 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
                            optimizer = bnb.optim.AdamW8bit(
                                self.model.parameters(),
                                lr=self.custom_learning_rate,
                                betas=(0.9, 0.999),
                                eps=1e-8,
                                weight_decay=0.01
                            )
                            
                            # –°–æ–∑–¥–∞–µ–º scheduler
                            scheduler = None
                            if self.args.max_steps > 0:
                                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                                    optimizer, T_max=self.args.max_steps
                                )
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö –¥–ª—è Trainer
                            self.optimizer = optimizer
                            self.lr_scheduler = scheduler
                            
                            self._log("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 8-bit AdamW –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (—ç–∫–æ–Ω–æ–º–∏—è ~25% –ø–∞–º—è—Ç–∏)")
                            return optimizer
                            
                        except Exception as e:
                            self._log(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞: {e}")
                            # –í–æ–∑–≤—Ä–∞—Ç –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É
                            
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
                    return super().create_optimizer()
                
                def _log(self, message):
                    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
                    try:
                        logger.info(message)
                    except:
                        print(f"OptimizedDonutTrainer: {message}")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
            use_8bit_optimizer = training_args.get('use_8bit_optimizer', True)
            learning_rate = training_args.get('learning_rate', 5e-5)
            
            # –°–æ–∑–¥–∞–µ–º trainer —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –ø–∞–º—è—Ç–∏
            self._log("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Trainer...")
            trainer = OptimizedDonutTrainer(
                model=model,
                args=train_args,
                train_dataset=dataset['train'],
                eval_dataset=dataset.get('validation'),
                data_collator=data_collator,
                callbacks=callbacks,
                use_8bit_optimizer=use_8bit_optimizer,
                learning_rate=learning_rate
            )
            self._log("‚úÖ Trainer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
            train_dataset_size = len(dataset['train'])
            batch_size = train_args.per_device_train_batch_size
            grad_accum = train_args.gradient_accumulation_steps
            effective_batch_size = batch_size * grad_accum
            steps_per_epoch = train_dataset_size // effective_batch_size
            total_steps = steps_per_epoch * train_args.num_train_epochs
            
            self._log(f"üìä –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏:")
            self._log(f"   üìÑ –†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {train_dataset_size}")
            self._log(f"   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
            self._log(f"   üîÑ Gradient accumulation: {grad_accum}")
            self._log(f"   üìà –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {effective_batch_size}")
            self._log(f"   üî¢ –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: {steps_per_epoch}")
            self._log(f"   üìä –í—Å–µ–≥–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {total_steps}")
            self._log(f"   ‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è (–ø—Ä–∏ 1 —Å–µ–∫/—à–∞–≥): {total_steps // 60} –º–∏–Ω")
            
            if self._stop_training:
                self._log("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ–∑–¥–∞–Ω–∏—è trainer")
                return None
                
            # 8. –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            self._log("\nüöÄ ===== –≠–¢–ê–ü 8: –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø =====")
            self._log("üéØ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –º–æ–¥–µ–ª–∏...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            class StopTrainingCallback(TrainerCallback):
                def __init__(self, donut_trainer):
                    self.donut_trainer = donut_trainer
                    
                def on_step_end(self, args, state, control, **kwargs):
                    if self.donut_trainer._stop_training:
                        control.should_training_stop = True
                        
            trainer.add_callback(StopTrainingCallback(self))
            
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è
            start_time = datetime.now()
            self._log(f"‚è∞ –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {start_time.strftime('%H:%M:%S')}")
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            training_result = trainer.train()
            
            if self._stop_training:
                self._log("‚èπÔ∏è –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return None
                
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
            end_time = datetime.now()
            duration = end_time - start_time
            self._log(f"‚è∞ –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è: {end_time.strftime('%H:%M:%S')}")
            self._log(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {duration}")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
            if hasattr(training_result, 'training_loss'):
                final_loss = training_result.training_loss
                self._log(f"üìâ –§–∏–Ω–∞–ª—å–Ω—ã–π training loss: {final_loss:.4f}")
                
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ loss
                if final_loss < 0.1:
                    loss_quality = "üü¢ –û—Ç–ª–∏—á–Ω—ã–π"
                elif final_loss < 0.5:
                    loss_quality = "üü° –•–æ—Ä–æ—à–∏–π"
                elif final_loss < 1.0:
                    loss_quality = "üü† –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π"
                else:
                    loss_quality = "üî¥ –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
                    
                self._log(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è: {loss_quality}")
                
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if hasattr(training_result, 'global_step') and training_result.global_step > 0:
                total_seconds = duration.total_seconds()
                steps_per_second = training_result.global_step / total_seconds
                seconds_per_step = total_seconds / training_result.global_step
                
                self._log(f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
                self._log(f"   üèÉ –®–∞–≥–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {steps_per_second:.2f}")
                self._log(f"   ‚è±Ô∏è –°–µ–∫—É–Ω–¥ –Ω–∞ —à–∞–≥: {seconds_per_step:.2f}")
                
                if seconds_per_step < 1:
                    perf_rating = "üöÄ –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ"
                elif seconds_per_step < 5:
                    perf_rating = "‚ö° –ë—ã—Å—Ç—Ä–æ"
                elif seconds_per_step < 10:
                    perf_rating = "üêé –ù–æ—Ä–º–∞–ª—å–Ω–æ"
                else:
                    perf_rating = "üêå –ú–µ–¥–ª–µ–Ω–Ω–æ"
                    
                self._log(f"   üìà –û—Ü–µ–Ω–∫–∞: {perf_rating}")
                
            # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self._log("\nüíæ ===== –≠–¢–ê–ü 9: –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò =====")
            self._log(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {output_dir}")
            
            trainer.save_model(output_dir)
            self._log("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            
            processor.save_pretrained(output_dir)
            self._log("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                'base_model': base_model_id,
                'task_type': task_type,
                'training_args': training_args,
                'created_at': datetime.now().isoformat(),
                'dataset_path': dataset_path,
                'training_duration': str(duration),
                'final_loss': getattr(training_result, 'training_loss', None),
                'total_steps': getattr(training_result, 'global_step', None)
            }
            
            metadata_path = os.path.join(output_dir, 'training_metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            self._log(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
                
            self._log(f"\nüéâ ========== –û–ë–£–ß–ï–ù–ò–ï DONUT –ó–ê–í–ï–†–®–ï–ù–û ==========")
            self._log(f"üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_dir}")
            self._log(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {duration}")
            self._log(f"üìä –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {getattr(training_result, 'global_step', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            
            return output_dir
            
        except Exception as e:
            self._log(f"\nüí• ========== –û–®–ò–ë–ö–ê –û–ë–£–ß–ï–ù–ò–Ø DONUT ==========")
            error_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
            self._log(error_msg)
            
            # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–∫–∏
            import traceback
            import sys
            
            self._log("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
            self._log(f"   Python –≤–µ—Ä—Å–∏—è: {sys.version}")
            self._log(f"   PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
            self._log(f"   CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                self._log(f"   CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}")
                self._log(f"   –¢–µ–∫—É—â–µ–µ CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {torch.cuda.current_device()}")
                self._log(f"   –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            
            self._log(f"   –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
            self._log(f"   –î–∞—Ç–∞—Å–µ—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(dataset_path) if 'dataset_path' in locals() else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
            self._log(f"   –ú–æ–¥–µ–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.app_config.MODELS_PATH}")
            self._log(f"   –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.app_config.TRAINED_MODELS_PATH}")
            
            # –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏
            self._log("\nüîç –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:")
            full_traceback = traceback.format_exc()
            for line in full_traceback.split('\n'):
                if line.strip():
                    self._log(f"   {line}")
            
            self.logger.error(f"DonutTrainer error: {error_msg}")
            self.logger.error(full_traceback)
            
            return None
            
    def _configure_model_for_training(self, model, processor, training_args):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        self._log("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏...")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_size = training_args.get('image_size', 384)
        self._log(f"   üñºÔ∏è –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_size}x{image_size}")
        if hasattr(model.config, 'encoder') and hasattr(model.config.encoder, 'image_size'):
            model.config.encoder.image_size = [image_size, image_size]
            self._log("   ‚úÖ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ encoder")
        else:
            self._log("   ‚ö†Ô∏è Encoder –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        max_length = training_args.get('max_length', 512)
        self._log(f"   üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {max_length}")
        if hasattr(model.config, 'decoder') and hasattr(model.config.decoder, 'max_length'):
            model.config.decoder.max_length = max_length
            self._log("   ‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤ decoder")
        else:
            self._log("   ‚ö†Ô∏è Decoder –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã")
            
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è VisionEncoderDecoderModel
        self._log("   üè∑Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤:")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        pad_token_id = processor.tokenizer.pad_token_id
        eos_token_id = processor.tokenizer.eos_token_id
        bos_token_id = processor.tokenizer.bos_token_id
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ –≥–ª–∞–≤–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        model.config.pad_token_id = pad_token_id
        model.config.eos_token_id = eos_token_id
        model.config.bos_token_id = bos_token_id
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º decoder_start_token_id
        # –û–±—ã—á–Ω–æ —ç—Ç–æ bos_token_id, –Ω–æ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º eos_token_id
        if bos_token_id is not None:
            decoder_start_token_id = bos_token_id
        elif eos_token_id is not None:
            decoder_start_token_id = eos_token_id
        else:
            # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º 0
            decoder_start_token_id = 0
            
        model.config.decoder_start_token_id = decoder_start_token_id
        self._log(f"     decoder_start_token_id: {decoder_start_token_id} ‚úÖ")
        
        self._log(f"     pad_token_id: {pad_token_id}")
        self._log(f"     eos_token_id: {eos_token_id}")
        self._log(f"     bos_token_id: {bos_token_id}")
        
        # –¢–∞–∫–∂–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ decoder, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if hasattr(model.config, 'decoder'):
            model.config.decoder.pad_token_id = pad_token_id
            model.config.decoder.eos_token_id = eos_token_id
            model.config.decoder.bos_token_id = bos_token_id
            model.config.decoder.decoder_start_token_id = decoder_start_token_id
            self._log("   ‚úÖ –¢–æ–∫–µ–Ω—ã —Ç–∞–∫–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ decoder –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–º–µ—Ä–µ —Å–ª–æ–≤–∞—Ä—è
        vocab_size = len(processor.tokenizer)
        self._log(f"   üìö –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {vocab_size}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self._log("   üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
        if hasattr(model.config, 'vocab_size'):
            model_vocab_size = model.config.vocab_size
            self._log(f"     –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è –º–æ–¥–µ–ª–∏: {model_vocab_size}")
            if model_vocab_size != vocab_size:
                self._log(f"     ‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —Å–ª–æ–≤–∞—Ä–µ–π!")
                
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        required_params = ['pad_token_id', 'eos_token_id', 'decoder_start_token_id']
        missing_params = []
        
        for param in required_params:
            if not hasattr(model.config, param) or getattr(model.config, param) is None:
                missing_params.append(param)
                
        if missing_params:
            self._log(f"   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {missing_params}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã {missing_params}")
        else:
            self._log("   ‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        self._log("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    def _create_training_arguments(self, training_args: dict, output_dir: str) -> TrainingArguments:
        """–°–æ–∑–¥–∞–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        
        # –ë–∞–∑–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        args = {
            'output_dir': output_dir,
            'num_train_epochs': training_args.get('num_train_epochs', 5),
            'per_device_train_batch_size': training_args.get('per_device_train_batch_size', 2),
            'per_device_eval_batch_size': training_args.get('per_device_eval_batch_size', 2),
            'gradient_accumulation_steps': training_args.get('gradient_accumulation_steps', 4),
            'learning_rate': training_args.get('learning_rate', 3e-5),
            'weight_decay': training_args.get('weight_decay', 0.01),
            'warmup_ratio': training_args.get('warmup_ratio', 0.1),
            'logging_steps': 10,
            'save_steps': training_args.get('save_steps', 500),
            'eval_steps': training_args.get('eval_steps', 500),
            'eval_strategy': 'steps',  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É—é –Ω–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
            'save_strategy': 'steps',
            'load_best_model_at_end': True,
            'metric_for_best_model': 'eval_loss',
            'greater_is_better': False,
            'save_total_limit': 3,
            'report_to': 'none',
            'remove_unused_columns': False,
            'dataloader_pin_memory': False,
        }
        
        # ‚ö° –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU
        if torch.cuda.is_available():
            self._log("üöÄ –ù–ê–°–¢–†–û–ô–ö–ê GPU –£–°–ö–û–†–ï–ù–ò–Ø:")
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è GPU (—É–±–∏—Ä–∞–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
            args['dataloader_num_workers'] = 0  # –ö–†–ò–¢–ò–ß–ù–û: 0 workers –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM
            args['dataloader_pin_memory'] = True  # –í–∫–ª—é—á–∞–µ–º –¥–ª—è GPU
            # –û—Ç–∫–ª—é—á–∞–µ–º group_by_length –¥–ª—è Donut (–Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å image+text –¥–∞—Ç–∞—Å–µ—Ç–æ–º)
            # args['group_by_length'] = True  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞—Ç—á–µ–π
            
            # FP16 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU
            if training_args.get('fp16', True):
                args['fp16'] = True
                self._log("   ‚úÖ FP16 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
            
            # üöÄ –ö–†–ò–¢–ò–ß–ù–´–ï –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM
            args['ddp_find_unused_parameters'] = False
            args['dataloader_persistent_workers'] = False  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            args['max_grad_norm'] = 1.0  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
            args['gradient_checkpointing'] = True  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞–µ–º
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Donut
            args['remove_unused_columns'] = False  # –ö–†–ò–¢–ò–ß–ù–û: False –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å image+text –∫–æ–ª–æ–Ω–∫–∞–º–∏
            args['prediction_loss_only'] = True  # –¢–æ–ª—å–∫–æ loss –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            self._log(f"   üéÆ GPU: {gpu_name}")
            self._log(f"   üíæ GPU –ø–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
            self._log(f"   ‚ö° CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
            self._log(f"   üß† Workers: {args['dataloader_num_workers']} (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –ø–∞–º—è—Ç–∏)")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            allocated_gb = torch.cuda.memory_allocated(0) / (1024**3)
            if allocated_gb > 1:
                self._log(f"   ‚ö†Ô∏è –£–∂–µ –≤—ã–¥–µ–ª–µ–Ω–æ {allocated_gb:.2f} GB –ø–∞–º—è—Ç–∏")
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                self._log(f"   üßπ –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞")
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –¥–ª—è GPU
            recommended_batch = min(4, max(1, int(gpu_memory // 6)))  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            current_batch = args['per_device_train_batch_size']
            if current_batch > recommended_batch:
                self._log(f"   ‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —É–º–µ–Ω—å—à–∏—Ç—å batch_size –¥–æ {recommended_batch} –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM")
            
            # üö® –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è RTX 4070 Ti
            if torch.cuda.is_available():
                current_gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                if current_gpu_memory_gb >= 11 and current_gpu_memory_gb <= 13:  # RTX 4070 Ti –¥–∏–∞–ø–∞–∑–æ–Ω
                    max_safe_batch = 1
                    if args['per_device_train_batch_size'] > max_safe_batch:
                        self._log(f"   üö® –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û —É–º–µ–Ω—å—à–∞–µ–º batch_size —Å {args['per_device_train_batch_size']} –¥–æ {max_safe_batch} –¥–ª—è RTX 4070 Ti")
                        args['per_device_train_batch_size'] = max_safe_batch
                        args['per_device_eval_batch_size'] = max_safe_batch
                        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º gradient accumulation –¥–ª—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏
                        if args['gradient_accumulation_steps'] < 8:
                            args['gradient_accumulation_steps'] = 8
                            self._log(f"   üìà –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º gradient_accumulation_steps –¥–æ 8 –¥–ª—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏")
            
        else:
            self._log("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU (–±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ)")
            args['dataloader_num_workers'] = 0
            args['fp16'] = False
            
        return TrainingArguments(**args)
        
    def _create_callbacks(self, processor, eval_dataset) -> List[TrainerCallback]:
        """–°–æ–∑–¥–∞–µ—Ç callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        callbacks = []
        
        # Progress callback
        if self.progress_callback or self.log_callback:
            callbacks.append(DonutProgressCallback(
                progress_callback=self.progress_callback,
                log_callback=self.log_callback
            ))
            
        # Metrics callback
        if eval_dataset:
            callbacks.append(DonutMetricsCallback(
                processor=processor,
                eval_dataset=eval_dataset,
                log_callback=self.log_callback
            ))
            
        # Early stopping
        callbacks.append(EarlyStoppingCallback(
            early_stopping_patience=3,
            early_stopping_threshold=0.001
        ))
        
        # GPU monitor callback
        callbacks.append(DonutGPUMonitorCallback(
            log_callback=self.log_callback
        ))
        
        return callbacks 

    def _apply_model_specific_optimizations(self, model, training_args: dict):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è Donut –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        # Donut specific patch –¥–ª—è VisionEncoderDecoderModel
        self._patch_model_forward(model)
        return model
    
    def _get_8bit_optimizer(self, model, learning_rate: float):
        """
        –°–æ–∑–¥–∞–µ—Ç 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        """
        if not BITSANDBYTES_AVAILABLE:
            self._log("‚ö†Ô∏è bitsandbytes –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: pip install bitsandbytes")
            return None
            
        try:
            # 8-bit AdamW –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            optimizer = bnb.optim.AdamW8bit(
                model.parameters(),
                lr=learning_rate,
                betas=(0.9, 0.999),
                eps=1e-8,
                weight_decay=0.01
            )
            
            self._log("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 8-bit AdamW –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (—ç–∫–æ–Ω–æ–º–∏—è ~25% –ø–∞–º—è—Ç–∏)")
            return optimizer
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞: {str(e)}")
            return None
    
    def _apply_memory_optimizations(self, model, training_args: dict):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
        """
        optimizations_applied = []
        
        # 1. LoRA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        use_lora = training_args.get('use_lora', True)
        if use_lora:
            model, lora_success = self._apply_lora_optimization(model, training_args)
            if lora_success:
                optimizations_applied.append("LoRA (–¥–æ 95% —ç–∫–æ–Ω–æ–º–∏–∏)")
        
        # 2. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π gradient checkpointing
        try:
            model.gradient_checkpointing_enable()
            optimizations_applied.append("Gradient Checkpointing")
        except:
            pass
            
        # 3. Freeze encoder (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        freeze_encoder = training_args.get('freeze_encoder', False)
        if freeze_encoder:
            try:
                # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º encoder, –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ decoder
                for name, param in model.named_parameters():
                    if 'encoder' in name:
                        param.requires_grad = False
                        
                trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
                total = sum(p.numel() for p in model.parameters())
                
                self._log(f"üßä Encoder –∑–∞–º–æ—Ä–æ–∂–µ–Ω. –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable:,} ({100*trainable/total:.1f}%)")
                optimizations_applied.append("Frozen Encoder")
                
            except Exception as e:
                self._log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å encoder: {e}")
        
        self._log(f"üöÄ –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {', '.join(optimizations_applied)}")
        return model 

    def _patch_model_forward(self, model):
        """
        –ü–∞—Ç—á–∏—Ç forward –º–µ—Ç–æ–¥ VisionEncoderDecoderModel –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å Donut
        –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–µ—Ä–µ–¥–∞—á–∏ labels –≤ encoder –∫–∞–∫ input_ids
        """
        original_forward = model.forward
        
        def patched_forward(pixel_values=None, labels=None, **kwargs):
            """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π forward –¥–ª—è VisionEncoderDecoderModel"""
            
            # –ö–†–ò–¢–ò–ß–ù–û: Encoder –ø–æ–ª—É—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ pixel_values
            encoder_inputs = {
                'pixel_values': pixel_values
            }
            
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è encoder
            # –ù–ï –ø–µ—Ä–µ–¥–∞–µ–º: labels, input_ids, attention_mask, decoder_input_ids
            encoder_outputs = model.encoder(**encoder_inputs)
            
            if labels is not None:
                # –û–±—É—á–µ–Ω–∏–µ: decoder –ø–æ–ª—É—á–∞–µ—Ç encoder_outputs –∏ labels
                decoder_input_ids = model._shift_right(labels) if hasattr(model, '_shift_right') else labels
                
                # –û—á–∏—â–∞–µ–º kwargs –æ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                decoder_kwargs = {k: v for k, v in kwargs.items() 
                                if k not in ['pixel_values', 'labels', 'input_ids', 'decoder_input_ids', 'decoder_attention_mask', 'decoder_inputs_embeds']}
                
                decoder_outputs = model.decoder(
                    input_ids=decoder_input_ids,
                    encoder_hidden_states=encoder_outputs.last_hidden_state,
                    labels=labels,
                    **decoder_kwargs
                )
                
                return decoder_outputs
            else:
                # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å: –∏—Å–ø–æ–ª—å–∑—É–µ–º generate
                return model.generate(
                    pixel_values=pixel_values,
                    **kwargs
                )
        
        # –ó–∞–º–µ–Ω—è–µ–º forward –º–µ—Ç–æ–¥
        model.forward = patched_forward
        self._log("üîß VisionEncoderDecoderModel.forward –ø–∞—Ç—á–µ–Ω –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å Donut")
        
        return model


    
