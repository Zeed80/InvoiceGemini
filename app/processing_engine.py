"""
–ú–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
"""
import os
import sys
import tempfile
import numpy as np
import re
import time  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç time
from abc import ABC, abstractmethod
from typing import List
from PIL import Image
import pytesseract
import json
import torch
from pdf2image import convert_from_path
from huggingface_hub import hf_hub_download
import uuid
import logging  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è logging

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–≥–µ—Ä
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

from transformers import (
    AutoProcessor,
    AutoModelForTokenClassification,
    AutoImageProcessor, 
    AutoTokenizer,
    VisionEncoderDecoderModel,
    DonutProcessor as HfDonutProcessor
)

# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Google GenAI
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

from . import config as app_config
from . import utils
from .settings_manager import settings_manager
from .base_processor import BaseProcessor  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º BaseProcessor –∏–∑ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
from .invoice_formatter import InvoiceFormatter  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º InvoiceFormatter –∏–∑ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
from app.processing.table_extractor import extract_table_items_from_layoutlm

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏
try:
    from .core.memory_manager import get_memory_manager
    from .core.resource_manager import get_resource_manager
    MEMORY_MANAGEMENT_AVAILABLE = True
except ImportError:
    MEMORY_MANAGEMENT_AVAILABLE = False
    logger.warning("–ú–æ–¥—É–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
try:
    from .core.smart_model_loader import get_smart_model_loader
    from .core.advanced_cache_manager import get_advanced_cache_manager
    OPTIMIZATION_AVAILABLE = True
except ImportError:
    OPTIMIZATION_AVAILABLE = False
    logger.warning("–ú–æ–¥—É–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞")

class ModelManager:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∑–∞–≥—Ä—É–∑–∫—É, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª—è–º.
    """
    
    def __init__(self):
        self.models = {} # –ö—ç—à –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ (LayoutLM, Donut)
        self.ocr_processor_instance = None
        self.gemini_processor_instance = None # –ö—ç—à –¥–ª—è GeminiProcessor
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã LLM
        self.plugin_manager = None
        self._init_llm_plugins()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä—ã —Ä–µ—Å—É—Ä—Å–æ–≤ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        self.memory_manager = get_memory_manager() if MEMORY_MANAGEMENT_AVAILABLE else None
        self.resource_manager = get_resource_manager() if MEMORY_MANAGEMENT_AVAILABLE else None
        
        if self.memory_manager:
            logger.info("–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        if self.resource_manager:
            logger.info("–ú–µ–Ω–µ–¥–∂–µ—Ä —Ä–µ—Å—É—Ä—Å–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.smart_loader = None
        self.advanced_cache = None
        
        if OPTIMIZATION_AVAILABLE:
            try:
                self.smart_loader = get_smart_model_loader()
                self.advanced_cache = get_advanced_cache_manager()
                logger.info("üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
                
                # –ü–æ–¥–∫–ª—é—á–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                if self.smart_loader:
                    self.smart_loader.model_loaded.connect(self._on_smart_model_loaded)
                    self.smart_loader.memory_warning.connect(self._on_memory_warning)
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
                self.smart_loader = None
                self.advanced_cache = None
        
        logger.debug("ModelManager.__init__ completed") 
    
    def _on_smart_model_loaded(self, model_id: str, load_time: float):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ SmartModelLoader"""
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_id} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f}—Å")
    
    def _on_memory_warning(self, free_memory_mb: int):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ—Ö–≤–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏"""
        logger.warning(f"‚ö†Ô∏è –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏: {free_memory_mb}MB")
        
    def analyze_file_queue(self, file_paths: list):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—á–µ—Ä–µ–¥—å —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏"""
        if self.smart_loader:
            self.smart_loader.analyze_file_queue(file_paths)
            logger.debug(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –æ—á–µ—Ä–µ–¥—å –∏–∑ {len(file_paths)} —Ñ–∞–π–ª–æ–≤")
    
    def get_cached_result(self, file_path: str, model_type: str) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not self.advanced_cache:
            return None
            
        try:
            file_hash = self.advanced_cache.calculate_file_hash(file_path)
            result = self.advanced_cache.get_cached_result(file_hash, model_type)
            if result:
                logger.debug(f"üíæ –ù–∞–π–¥–µ–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {file_path} ({model_type})")
            return result
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫—ç—à–∞ –¥–ª—è {file_path}: {e}")
            return None
    
    def cache_result(self, file_path: str, model_type: str, result: dict, priority: int = 0) -> bool:
        """–ö—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not self.advanced_cache:
            return False
            
        try:
            file_hash = self.advanced_cache.calculate_file_hash(file_path)
            success = self.advanced_cache.cache_result(file_hash, model_type, result, file_path, priority)
            if success:
                logger.debug(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω –¥–ª—è {file_path} ({model_type})")
            return success
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è {file_path}: {e}")
            return False
    
    def get_optimization_statistics(self) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
        stats = {}
        
        if self.smart_loader:
            stats['smart_loader'] = self.smart_loader.get_statistics()
        
        if self.advanced_cache:
            stats['advanced_cache'] = self.advanced_cache.get_statistics()
            
        return stats
        
    def get_model(self, model_type):
        model_type_lower = model_type.lower()
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω SmartModelLoader, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if self.smart_loader:
            try:
                smart_model = self.smart_loader.get_model(model_type_lower, blocking=True)
                if smart_model:
                    logger.debug(f"ü§ñ –ú–æ–¥–µ–ª—å {model_type_lower} –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ SmartModelLoader")
                    return smart_model
                else:
                    logger.warning(f"SmartModelLoader –Ω–µ —Å–º–æ–≥ –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_type_lower}, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ SmartModelLoader –¥–ª—è {model_type_lower}: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –∑–∞–≥—Ä—É–∑–∫–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
        if self.memory_manager:
            can_load, message = self.memory_manager.can_load_model(model_type_lower)
            if not can_load:
                logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {message}")
                raise MemoryError(message)
        
        if model_type_lower == 'layoutlm':
            # NEW: –õ–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∫–∞–∫—É—é –º–æ–¥–µ–ª—å LayoutLM –∑–∞–≥—Ä—É–∂–∞—Ç—å
            active_type = settings_manager.get_active_layoutlm_model_type()
            model_identifier_to_load = ""
            is_custom_model = False
            
            if active_type == 'custom':
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
                custom_model_name = settings_manager.get_string('Models', 'custom_layoutlm_model_name', app_config.DEFAULT_CUSTOM_LAYOUTLM_MODEL_NAME)
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ trained_models
                model_identifier_to_load = os.path.join(app_config.TRAINED_MODELS_PATH, custom_model_name)
                is_custom_model = True  
                logger.debug(f"ModelManager: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–π LayoutLM –º–æ–¥–µ–ª–∏: {model_identifier_to_load}, is_custom={is_custom_model}")
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å Hugging Face
                model_identifier_to_load = settings_manager.get_string('Models', 'layoutlm_id', app_config.LAYOUTLM_MODEL_ID)
                print(f"DEBUG: ModelManager: –ó–∞–≥—Ä—É–∑–∫–∞ Hugging Face LayoutLM –º–æ–¥–µ–ª–∏: {model_identifier_to_load}, is_custom={is_custom_model}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—ç—à-–∫–ª—é—á, —É—á–∏—Ç—ã–≤–∞—è –∏ —Ç–∏–ø –º–æ–¥–µ–ª–∏ (custom/hf), –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä
            cache_key = f"layoutlm_{is_custom_model}_{model_identifier_to_load.replace(os.sep, '_')}"
            if cache_key not in self.models or self.models[cache_key] is None:
                print(f"DEBUG: ModelManager: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ LayoutLMProcessor —Å model_id={model_identifier_to_load}, is_custom={is_custom_model}")
                ocr_processor = self.get_ocr_processor()
                self.models[cache_key] = LayoutLMProcessor(ocr_processor, model_identifier_to_load, is_custom_model)
            
            return self.models[cache_key]
            
        elif model_type_lower == 'donut':
            model_id = settings_manager.get_string('Models', 'donut_id', app_config.DONUT_MODEL_ID)
            cache_key = f"donut_{model_id.replace(os.sep, '_')}"
            if cache_key not in self.models or self.models[cache_key] is None:
                print(f"DEBUG: ModelManager: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ DonutProcessor —Å model_id={model_id}")
                self.models[cache_key] = DonutProcessorImpl(model_id)
            return self.models[cache_key]

        elif model_type_lower == 'gemini':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–¥–Ω–∏–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
            if self.gemini_processor_instance is None or \
               (hasattr(self.gemini_processor_instance, 'model_id') and \
                self.gemini_processor_instance.model_id != settings_manager.get_string('Gemini', 'sub_model_id', app_config.GEMINI_MODEL_ID)):
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º GeminiProcessor –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
                from .gemini_processor import GeminiProcessor
                print("DEBUG: ModelManager: (–ü–µ—Ä–µ)—Å–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ GeminiProcessor")
                self.gemini_processor_instance = GeminiProcessor()
            return self.gemini_processor_instance
            
        elif model_type_lower == 'trocr':
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ TrOCR –º–æ–¥–µ–ª–µ–π
            # –ü–æ–ª—É—á–∞–µ–º model_id –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            model_identifier = settings_manager.get_string('Models', 'trocr_model_id', 'microsoft/trocr-base-printed')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –ø—É—Ç–∏
            is_custom = not model_identifier.startswith('microsoft/')
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—ç—à-–∫–ª—é—á
            cache_key = f"trocr_{model_identifier.replace(os.sep, '_').replace('/', '_')}"
            
            if cache_key not in self.models or self.models[cache_key] is None:
                print(f"DEBUG: ModelManager: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ TrOCRProcessor —Å model_id={model_identifier}")
                print(f"DEBUG: ModelManager: –ú–æ–¥–µ–ª—å {'–∫–∞—Å—Ç–æ–º–Ω–∞—è' if is_custom else 'HuggingFace'}")
                from .trocr_processor import TrOCRProcessor
                self.models[cache_key] = TrOCRProcessor(model_name=model_identifier)
                
            return self.models[cache_key]
            
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

    def get_ocr_processor(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä OCRProcessor."""
        if self.ocr_processor_instance is None:
            print("DEBUG: ModelManager creating new OCRProcessor instance")
            self.ocr_processor_instance = OCRProcessor()
        return self.ocr_processor_instance

    def load_layoutlm_model(self, model_id_or_path, is_custom=False):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å LayoutLM —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º ID –∏–ª–∏ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏.
        
        Args:
            model_id_or_path (str): ID –º–æ–¥–µ–ª–∏ –¥–ª—è Hugging Face –∏–ª–∏ –ø—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            is_custom (bool): –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, —á—Ç–æ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –º–æ–¥–µ–ª—å
            
        Returns:
            bool: True, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, –∏–Ω–∞—á–µ False
        """
        print(f"DEBUG: ModelManager.load_layoutlm_model –≤—ã–∑–≤–∞–Ω —Å model_id_or_path='{model_id_or_path}', is_custom={is_custom}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—ç—à-–∫–ª—é—á –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
        cache_key = f"layoutlm_{is_custom}_{model_id_or_path.replace(os.sep, '_')}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        create_new = False
        if cache_key not in self.models or self.models[cache_key] is None:
            create_new = True
        elif hasattr(self.models[cache_key], 'model_id_loaded') and self.models[cache_key].model_id_loaded != model_id_or_path:
            create_new = True
        
        if create_new:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
            print(f"DEBUG: ModelManager: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ LayoutLMProcessor —Å model_id={model_id_or_path}, is_custom={is_custom}")
            ocr_processor = self.get_ocr_processor()
            self.models[cache_key] = LayoutLMProcessor(ocr_processor, model_id_or_path, is_custom)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if not self.models[cache_key].is_loaded:
            success = self.models[cache_key].load_model()
            if success:
                # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ settings_manager
                if is_custom:
                    settings_manager.set_value('Models', 'active_layoutlm_model_type', 'custom')
                    settings_manager.set_value('Models', 'custom_layoutlm_model_name', os.path.basename(model_id_or_path))
                else:
                    settings_manager.set_value('Models', 'active_layoutlm_model_type', 'huggingface')
                    settings_manager.set_value('Models', 'layoutlm_id', model_id_or_path)
                settings_manager.save_settings()
            return success
        else:
            return True  # –£–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞

    def clear_layoutlm_model(self):
        """
        –í—ã–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ LayoutLM –∏–∑ –ø–∞–º—è—Ç–∏.
        
        Returns:
            bool: True, –µ—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        print("DEBUG: ModelManager.clear_layoutlm_model –≤—ã–∑–≤–∞–Ω")
        
        # –ù–∞—Ö–æ–¥–∏–º –∏ —É–¥–∞–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å LayoutLM
        keys_to_delete = []
        for key in self.models.keys():
            if key.startswith('layoutlm_'):
                keys_to_delete.append(key)
                
        # –£–¥–∞–ª—è–µ–º –∫–∞–∂–¥—ã–π –∫–ª—é—á
        for key in keys_to_delete:
            if self.models[key] is not None:
                # –ï—Å–ª–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ –µ—Å—Ç—å –º–µ—Ç–æ–¥ unload_model, –≤—ã–∑—ã–≤–∞–µ–º –µ–≥–æ
                if hasattr(self.models[key], 'unload_model') and callable(self.models[key].unload_model):
                    try:
                        self.models[key].unload_model()
                    except Exception as e:
                        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ LayoutLM: {e}")
                
                # –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
                if hasattr(self.models[key], 'model'):
                    try:
                        self.models[key].model = None
                    except Exception:
                        pass
                    
                if hasattr(self.models[key], 'processor'):
                    try:
                        self.models[key].processor = None
                    except Exception:
                        pass
                    
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏
                if hasattr(self.models[key], 'is_loaded'):
                    self.models[key].is_loaded = False
                
            # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑ —Å–ª–æ–≤–∞—Ä—è
            del self.models[key]
            
        # –í—ã–∑—ã–≤–∞–µ–º —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        import gc
        gc.collect()
        
        print(f"DEBUG: ModelManager: LayoutLM –º–æ–¥–µ–ª–∏ –≤—ã–≥—Ä—É–∂–µ–Ω—ã, —É–¥–∞–ª–µ–Ω–æ {len(keys_to_delete)} —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤")
        return True

    def get_gemini_processor(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä GeminiProcessor."""
        return self.get_model('gemini')
    
    def _init_llm_plugins(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º—É LLM –ø–ª–∞–≥–∏–Ω–æ–≤"""
        try:
            from .plugins.unified_plugin_manager import get_unified_plugin_manager
            self.plugin_manager = get_unified_plugin_manager()
            print("[OK] –°–∏—Å—Ç–µ–º–∞ LLM –ø–ª–∞–≥–∏–Ω–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        except ImportError as e:
            print(f"[WARN] –°–∏—Å—Ç–µ–º–∞ LLM –ø–ª–∞–≥–∏–Ω–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            self.plugin_manager = None
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM –ø–ª–∞–≥–∏–Ω–æ–≤: {e}")
            self.plugin_manager = None
    
    def get_llm_plugin_manager(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä LLM –ø–ª–∞–≥–∏–Ω–æ–≤"""
        return self.plugin_manager
    
    def get_llm_plugin(self, plugin_id: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –ø–ª–∞–≥–∏–Ω–∞
        
        Args:
            plugin_id: ID –ø–ª–∞–≥–∏–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'llama', 'mistral')
            
        Returns:
            BaseLLMPlugin –∏–ª–∏ None
        """
        if not self.plugin_manager:
            return None
        
        return self.plugin_manager.get_plugin_instance(plugin_id)
    
    def create_llm_plugin(self, plugin_id: str):
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –ø–ª–∞–≥–∏–Ω–∞
        
        Args:
            plugin_id: ID –ø–ª–∞–≥–∏–Ω–∞
            
        Returns:
            BaseLLMPlugin –∏–ª–∏ None
        """
        if not self.plugin_manager:
            return None
        
        return self.plugin_manager.create_plugin_instance(plugin_id)
    
    def get_available_llm_plugins(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –ø–ª–∞–≥–∏–Ω–æ–≤"""
        if not self.plugin_manager:
            return []
        
        return self.plugin_manager.get_available_plugins()
    
    def download_model(self, model_type, model_id=None, is_custom=False):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ Hugging Face Hub –∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
        is_custom –∑–¥–µ—Å—å –±–æ–ª—å—à–µ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Ç.–∫. LayoutLMProcessor —Å–∞–º —Ä–µ—à–∏—Ç, —á—Ç–æ –¥–µ–ª–∞—Ç—å.
        """
        try:
            # –î–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π LayoutLM –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ,
            # —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —É–∂–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ. –ù–æ –¥–ª—è HF –º–æ–¥–µ–ª–µ–π - –¥–∞.
            if model_type.lower() == 'layoutlm' and is_custom:
                print(f"INFO: ModelManager: –î–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π LayoutLM –º–æ–¥–µ–ª–∏ '{model_id}' —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.")
                # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–∞–º –ø–æ–ø—Ä–æ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
                processor = self.get_model(model_type) # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç–∞–Ω—Å, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å
                return processor.is_loaded # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            
            processor = self.get_model(model_type)
            # –î–ª—è LayoutLM –∏ Donut, model_id –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤–Ω—É—Ç—Ä–∏ get_model
            # –∏ –ø–µ—Ä–µ–¥–∞–Ω –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞. –ó–∞—Ç–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤—ã–∑–æ–≤–µ—Ç —Å–≤–æ–π load_model.
            # –ó–¥–µ—Å—å –º—ã –ø—Ä–æ—Å—Ç–æ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ–º —ç—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.
            if not processor.is_loaded:
                # model_id –¥–ª—è LayoutLM –∏ Donut —É–∂–µ —É—á—Ç–µ–Ω –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≤ get_model
                # –î–ª—è Gemini, model_id (sub_model_id) —Ç–∞–∫–∂–µ —É—á—Ç–µ–Ω
                return processor.load_model() # –í—ã–∑—ã–≤–∞–µ–º load_model –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, —Ç.–∫. ID —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
            else:
                # –ï—Å–ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –º–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å —Å –Ω–æ–≤—ã–º ID, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
                # –ù–æ —Ç–µ–∫—É—â–∞—è –ª–æ–≥–∏–∫–∞ get_model –¥–æ–ª–∂–Ω–∞ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä, –µ—Å–ª–∏ ID –∏–∑–º–µ–Ω–∏–ª—Å—è.
                # –ü–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ —É–∂–µ is_loaded.
                if model_id and hasattr(processor, 'model_id_loaded') and processor.model_id_loaded != model_id and not is_custom:
                    print(f"INFO: ModelManager: –ú–æ–¥–µ–ª—å {model_type} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –Ω–æ —Å –¥—Ä—É–≥–∏–º ID. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Å {model_id}...")
                    return processor.load_model(model_id)
                return True # –£–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏/–ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–∏ {model_type} (ID/Path: {model_id}): {str(e)}")
            import traceback
            traceback.print_exc()
            return False


class OCRProcessor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OCR —á–µ—Ä–µ–∑ Tesseract.
    """
    
    def __init__(self):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Tesseract
        tesseract_path = settings_manager.get_string('Paths', 'tesseract_path', '')
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
            print(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—É—Ç—å Tesseract: {tesseract_path}")
        else:
            print("–ü—É—Ç—å Tesseract –Ω–µ —É–∫–∞–∑–∞–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π)")

    def get_tesseract_path(self):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–º—É —Ñ–∞–π–ª—É Tesseract.
        
        Returns:
            str: –ü—É—Ç—å –∫ Tesseract –∏–ª–∏ None, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π
        """
        return pytesseract.pytesseract.tesseract_cmd if hasattr(pytesseract.pytesseract, 'tesseract_cmd') else None
        
    @staticmethod
    def validate_tesseract():
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ Tesseract OCR –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ª–∏ –ø—É—Ç—å –∫ –Ω–µ–º—É.
        
        Returns:
            bool: True, –µ—Å–ª–∏ Tesseract –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ False
        """
        if not utils.is_tesseract_installed():
            return False
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—É—Ç—å –∫ tesseract.exe –¥–ª—è pytesseract
        if app_config.TESSERACT_PATH:
            pytesseract.pytesseract.tesseract_cmd = app_config.TESSERACT_PATH
        
        return True
    
    @staticmethod
    def process_image(image_path, lang='eng'):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ bounding box'—ã –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Tesseract OCR.
        –¢–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç PDF-—Ñ–∞–π–ª—ã, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è –∏—Ö –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        
        Args:
            image_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ PDF
            lang (str): –Ø–∑—ã–∫ OCR (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'eng')
            
        Returns:
            tuple: (—Ç–µ–∫—Å—Ç, —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å bounding box'–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–º)
        """
        if not OCRProcessor.validate_tesseract():
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–∑—ã–≤–∞—é—â–∏–π –∫–æ–¥ –º–æ–≥ —ç—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
            print("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: Tesseract OCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. OCR –Ω–µ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω.")
            return "", [] 
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        if image_path.lower().endswith('.pdf'):
            return OCRProcessor.process_pdf(image_path, lang)
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"–û–®–ò–ë–ö–ê OCR: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {image_path}")
            return "", []
        except Exception as e:
            print(f"–û–®–ò–ë–ö–ê OCR: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_path} - {e}")
            return "", []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        try:
            text = pytesseract.image_to_string(image, lang=lang)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –±–æ–∫—Å–∞—Ö (—Å —É—Ä–æ–≤–Ω–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ 5 - —Å–∏–º–≤–æ–ª—ã)
            boxes_data = pytesseract.image_to_data(image, lang=lang, output_type=pytesseract.Output.DICT)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Å–ª–æ–≤–∞—Ö
            words = []
            n_boxes = len(boxes_data['level'])
            for i in range(n_boxes):
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –Ω–µ —Å–∏–º–≤–æ–ª—ã)
                if boxes_data['text'][i].strip() and int(boxes_data['conf'][i]) > -1: # conf -1 –¥–ª—è –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö
                    word = {
                        'text': boxes_data['text'][i],
                        'confidence': float(boxes_data['conf'][i]),
                        'x': int(boxes_data['left'][i]),
                        'y': int(boxes_data['top'][i]),
                        'width': int(boxes_data['width'][i]),
                        'height': int(boxes_data['height'][i]),
                        'page_num': 1  # –í—Å–µ–≥–¥–∞ 1, —Ç–∞–∫ –∫–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    }
                    words.append(word)
            
            print(f"[OCR DEBUG] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ {len(words)} —Å–ª–æ–≤ –≤ —Ñ–∞–π–ª–µ {os.path.basename(image_path)}")
            print(f"[OCR DEBUG] –ü–µ—Ä–≤—ã–µ 5 —Å–ª–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:")
            for i, word in enumerate(words[:5]):
                print(f"  {i+1}. '{word['text']}' ({word['x']}, {word['y']}, {word['width']}, {word['height']})")
            
            return text, words
        except pytesseract.TesseractNotFoundError:
            print("–û–®–ò–ë–ö–ê OCR: Tesseract –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö.")
            return "", []
        except Exception as e:
            print(f"–û–®–ò–ë–ö–ê OCR: –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Tesseract –¥–ª—è {image_path} - {e}")
            return "", []
    
    @staticmethod
    def process_pdf(pdf_path, lang='eng'):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF-—Ñ–∞–π–ª, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è –µ–≥–æ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω—è—è OCR.
        
        Args:
            pdf_path (str): –ü—É—Ç—å –∫ PDF-—Ñ–∞–π–ª—É
            lang (str): –Ø–∑—ã–∫ OCR
            
        Returns:
            tuple: (—Ç–µ–∫—Å—Ç, —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å bounding box'–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–º)
        """
        try:
            print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {pdf_path}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            temp_dir = tempfile.mkdtemp()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ poppler
                poppler_path = app_config.POPPLER_PATH if hasattr(app_config, 'POPPLER_PATH') else None
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –Ω–∞—á–∞–ª–∞)
                images = convert_from_path(
                    pdf_path, 
                    dpi=300, 
                    first_page=1, 
                    last_page=1,
                    poppler_path=poppler_path
                )
                
                if not images:
                    print(f"–û–®–ò–ë–ö–ê OCR: –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {pdf_path}")
                    return "", []
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                temp_image_path = os.path.join(temp_dir, "temp_pdf_page.jpg")
                images[0].save(temp_image_path, "JPEG")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é OCR
                text, words = OCRProcessor.process_image(temp_image_path, lang)
                
                return text, words
                
            except Exception as e:
                print(f"–û–®–ò–ë–ö–ê OCR: –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                import traceback
                traceback.print_exc()
                return "", []
            
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            try:
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
            except (OSError, PermissionError) as e:
                logging.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {temp_dir}: {e}")
    
    @staticmethod
    def get_available_languages():
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤ Tesseract OCR.
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∫–æ–¥–æ–≤ —è–∑—ã–∫–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤ Tesseract
        """
        if not OCRProcessor.validate_tesseract():
            return ['eng']  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤ –∏–∑ Tesseract
            langs = pytesseract.get_languages()
            return langs
        except (pytesseract.TesseractError, RuntimeError, OSError) as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤ Tesseract: {e}")
            return ['eng']  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π

    @staticmethod
    def process_file(image_path, lang=None):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å TrainingDataPreparator.
        
        Args:
            image_path (str): –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            lang (str): –Ø–∑—ã–∫ OCR (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            
        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ OCR: words, width, height
        """
        if lang is None:
            # –ü–æ–ª—É—á–∞–µ–º —è–∑—ã–∫ OCR –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            lang = settings_manager.get_string('OCR', 'language', 'eng')
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ process_image
        text, word_data = OCRProcessor.process_image(image_path, lang)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è TrainingDataPreparator
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(image_path)
            width, height = image.size
            image.close()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç, –æ–∂–∏–¥–∞–µ–º—ã–π TrainingDataPreparator
            words = []
            for word in word_data:
                try:
                    # –°–æ–∑–¥–∞–µ–º bbox –≤ —Ñ–æ—Ä–º–∞—Ç–µ [x1, y1, x2, y2]
                    x1 = word['x']
                    y1 = word['y']
                    x2 = x1 + word['width']
                    y2 = y1 + word['height']
                    
                    words.append({
                        'text': word['text'],
                        'bbox': [x1, y1, x2, y2],
                        'confidence': word.get('confidence', 0)
                    })
                except KeyError as e:
                    print(f"–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ü—Ä–æ–ø—É—Å–∫ —Å–ª–æ–≤–∞ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–ª—é—á–∞: {e}")
            
            return {
                'words': words,
                'text': text,
                'width': width,
                'height': height
            }
        except Exception as e:
            print(f"–û–®–ò–ë–ö–ê –≤ OCRProcessor.process_file: {e}")
            import traceback
            print(traceback.format_exc())
            return {
                'words': [],
                'text': text,
                'width': 0,
                'height': 0
            }


class LayoutLMProcessor(BaseProcessor):
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ LayoutLMv3.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Tesseract OCR –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –µ–≥–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç.
    """
    def __init__(self, ocr_processor, model_identifier, is_custom):
        print(f"DEBUG: LayoutLMProcessor.__init__ called with identifier: '{model_identifier}', is_custom: {is_custom}") 
        self.model_identifier_to_load = model_identifier # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ –±—ã–ª–æ –ø–µ—Ä–µ–¥–∞–Ω–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        self.is_custom_model = is_custom
        
        self.processor = None
        self.model = None
        self.is_loaded = False
        self.ocr_processor = ocr_processor 
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"LayoutLMProcessor –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –≠—Ç–∏ –ø–æ–ª—è –±—É–¥—É—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        self.model_id_loaded = None # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π ID/–ø—É—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.is_custom_loaded = None # –§–ª–∞–≥, —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è
        
    def load_model(self, model_id_override=None): # model_id_override –∑–¥–µ—Å—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –ª—É—á—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å LayoutLM.
        –ï—Å–ª–∏ self.is_custom_model is True, self.model_identifier_to_load –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–º –ø—É—Ç–µ–º.
        –ò–Ω–∞—á–µ, —ç—Ç–æ HF ID.
        """
        actual_identifier_to_use = model_id_override if model_id_override else self.model_identifier_to_load
        is_loading_custom = self.is_custom_model if model_id_override is None else False # –ï—Å–ª–∏ –æ–≤–µ—Ä—Ä–∞–π–¥, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —ç—Ç–æ HF ID

        if not actual_identifier_to_use:
            self._log("[–û–®–ò–ë–ö–ê LayoutLM] –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏ (ID –∏–ª–∏ –ø—É—Ç—å) –Ω–µ —É–∫–∞–∑–∞–Ω.")
            self.is_loaded = False
            return False

        self._log(f"–ó–∞–≥—Ä—É–∑–∫–∞ LayoutLM –º–æ–¥–µ–ª–∏: '{actual_identifier_to_use}' (–ö–∞—Å—Ç–æ–º–Ω–∞—è: {is_loading_custom})...")
        
        model_cache_dir_for_hf = os.path.join(app_config.MODELS_PATH, 'layoutlm', actual_identifier_to_use.replace("/", "_"))
        # –î–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, actual_identifier_to_use —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –ø—É—Ç–µ–º, –∏ –∫—ç—à HF –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–æ–º –∂–µ —Å–º—ã—Å–ª–µ
        # –ù–æ AutoProcessor.from_pretrained –∏ AutoModelForTokenClassification –º–æ–≥—É—Ç –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—ã—Ç–∞—Ç—å—Å—è —á—Ç–æ-—Ç–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å,
        # –µ—Å–ª–∏ –∏–º –ø–µ—Ä–µ–¥–∞—Ç—å –ø—É—Ç—å, –∫–æ—Ç–æ—Ä—ã–π –ø–æ—Ö–æ–∂ –Ω–∞ HF ID. –ü–æ—ç—Ç–æ–º—É –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å local_files_only=True –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö.

        offline_mode = app_config.OFFLINE_MODE
        token = app_config.HF_TOKEN
        
        source_path_for_load = actual_identifier_to_use # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —ç—Ç–æ HF ID –∏–ª–∏ –ø—Ä—è–º–æ–π –ø—É—Ç—å –∫ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏

        try:
            if is_loading_custom:
                # –î–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏, source_path_for_load - —ç—Ç–æ –ø—Ä—è–º–æ–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ
                if not os.path.isdir(source_path_for_load):
                    self._log(f"[–û–®–ò–ë–ö–ê LayoutLM] –ü—É—Ç—å –∫ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {source_path_for_load}")
                    self.is_loaded = False
                    return False
                self._log(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏ LayoutLM –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏: {source_path_for_load}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤
                required_files = ['config.json', 'pytorch_model.bin']
                missing_files = [f for f in required_files if not os.path.exists(os.path.join(source_path_for_load, f))]
                if missing_files:
                    self._log(f"[–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï] –í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing_files)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ preprocessor_config.json, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ–º
                preprocessor_config_path = os.path.join(source_path_for_load, 'preprocessor_config.json')
                if not os.path.exists(preprocessor_config_path):
                    self._log(f"[–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï] –§–∞–π–ª preprocessor_config.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π")
                    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π preprocessor_config.json –¥–ª—è LayoutLM
                    base_preprocessor_config = {
                        "apply_ocr": False,
                        "do_resize": True,
                        "do_thumbnail": True,
                        "image_mean": [0.5, 0.5, 0.5],
                        "image_processor_type": "LayoutLMv3ImageProcessor",
                        "image_std": [0.5, 0.5, 0.5],
                        "processor_class": "LayoutLMv3Processor",
                        "size": {"height": 224, "width": 224},
                        "tokenizer_class": "LayoutLMv3Tokenizer"
                    }
                    try:
                        import json
                        with open(preprocessor_config_path, 'w', encoding='utf-8') as f:
                            json.dump(base_preprocessor_config, f, indent=2)
                        self._log(f"–°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π preprocessor_config.json –≤ {preprocessor_config_path}")
                    except Exception as e_create:
                        self._log(f"[–û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å preprocessor_config.json: {e_create}")
                
                # –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏, HF –∫—ç—à –Ω–µ –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                # local_files_only=True –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –±—Ä–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –∏–∑ —ç—Ç–æ–≥–æ –ø—É—Ç–∏.
                try:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
                    self.processor = AutoProcessor.from_pretrained(source_path_for_load, apply_ocr=False, local_files_only=True, token=token)
                except Exception as e_proc:
                    self._log(f"[–û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä: {e_proc}")
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä, –ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –µ–≥–æ –∏–∑ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
                    try:
                        from transformers import LayoutLMv3Processor, LayoutLMv3TokenizerFast, LayoutLMv3ImageProcessor
                        base_tokenizer = LayoutLMv3TokenizerFast.from_pretrained("microsoft/layoutlmv3-base", local_files_only=False, token=token)
                        base_image_processor = LayoutLMv3ImageProcessor(apply_ocr=False)
                        self.processor = LayoutLMv3Processor(base_tokenizer, base_image_processor)
                        self._log("–°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä LayoutLMv3 –∏–∑ microsoft/layoutlmv3-base")
                    except Exception as e_base_proc:
                        self._log(f"[–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä: {e_base_proc}")
                        self.is_loaded = False
                        return False
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                try:
                    self.model = AutoModelForTokenClassification.from_pretrained(source_path_for_load, local_files_only=True, token=token)
                except Exception as e_model:
                    self._log(f"[–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e_model}")
                    self.is_loaded = False
                    return False
            else:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face (—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–∞ –∏–∑ –∫—ç—à–∞ HF)
                self._log(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LayoutLM —Å Hugging Face: {source_path_for_load} (Offline: {offline_mode})")
                os.makedirs(model_cache_dir_for_hf, exist_ok=True)
                
                self.processor = AutoProcessor.from_pretrained(
                    source_path_for_load,
                    apply_ocr=False, 
                    cache_dir=model_cache_dir_for_hf, # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º cache_dir
                    local_files_only=offline_mode,
                    token=token
                )
                self.model = AutoModelForTokenClassification.from_pretrained(
                    source_path_for_load,
                    cache_dir=model_cache_dir_for_hf, # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º cache_dir
                    local_files_only=offline_mode,
                    token=token
                )
            
            self.model.to(self.device)
            self._log(f"–ú–æ–¥–µ–ª—å LayoutLM '{actual_identifier_to_use}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            self.is_loaded = True
            self.model_id_loaded = actual_identifier_to_use # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            self.is_custom_loaded = is_loading_custom      # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥ —Ç–∏–ø–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            return True
        
        except Exception as e_load:
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –∫–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å –∏ –Ω–µ –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º, –ò–õ–ò –µ—Å–ª–∏ —ç—Ç–æ –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º, –Ω–æ –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
            if not is_loading_custom and not offline_mode:
                self._log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å LayoutLM ('{actual_identifier_to_use}') –Ω–∞–ø—Ä—è–º—É—é, –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã –≤ –∫—ç—à: {e_load}")
                try:
                    # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –Ω—É–∂–Ω–æ, –µ—Å–ª–∏ cache_dir –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å from_pretrained
                    # –ù–æ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ from_pretrained –Ω–µ —Å–∫–∞—á–∏–≤–∞–µ—Ç —Å–∞–º–∞
                    required_files = getattr(self.model.config, '_model_type', 'layoutlm') # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
                    # –ó–¥–µ—Å—å –Ω—É–∂–Ω–∞ –±–æ–ª–µ–µ —É–º–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤, –Ω–æ –¥–ª—è LayoutLM —ç—Ç–æ –æ–±—ã—á–Ω–æ:
                    config_files = ['config.json', 'preprocessor_config.json', 'tokenizer.json', 'special_tokens_map.json', 'tokenizer_config.json']
                    model_files = ['pytorch_model.bin'] # –∏–ª–∏ .safetensors
                    # –î–ª—è LayoutLM (–Ω–µ v3) —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å –¥—Ä—É–≥–∏–º–∏.
                    # –≠—Ç–æ –æ—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è, from_pretrained –¥–æ–ª–∂–Ω–∞ —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è –ª—É—á—à–µ.
                    
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∫—ç—à –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π
                    if os.path.exists(model_cache_dir_for_hf):
                        import shutil
                        self._log(f"–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞ –¥–ª—è {actual_identifier_to_use} –≤ {model_cache_dir_for_hf}")
                        try: shutil.rmtree(model_cache_dir_for_hf)
                        except Exception as e_rm: self._log(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞: {e_rm}")
                    os.makedirs(model_cache_dir_for_hf, exist_ok=True)

                    for file_name in config_files + model_files:
                        try:
                            hf_hub_download(
                                repo_id=actual_identifier_to_use, 
                                filename=file_name,
                                cache_dir=model_cache_dir_for_hf, # –°–∫–∞—á–∏–≤–∞–µ–º –≤ –Ω–∞—à –∫—ç—à
                                local_files_only=False, # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
                                token=token,
                                force_download=True 
                            )
                            self._log(f"–§–∞–π–ª {file_name} –¥–ª—è LayoutLM –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {model_cache_dir_for_hf}")
                        except Exception as e_file_dl:
                            self._log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª {file_name} –¥–ª—è LayoutLM ({actual_identifier_to_use}): {e_file_dl}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –æ–Ω –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω.")
                    
                    # –ü–æ—Å–ª–µ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞
                    self.processor = AutoProcessor.from_pretrained(model_cache_dir_for_hf, apply_ocr=False, local_files_only=True, token=token)
                    self.model = AutoModelForTokenClassification.from_pretrained(model_cache_dir_for_hf, local_files_only=True, token=token)
                    self.model.to(self.device)
                    self._log(f"–ú–æ–¥–µ–ª—å LayoutLM '{actual_identifier_to_use}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø–æ—Å–ª–µ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤ –∫—ç—à.")
                    self.is_loaded = True
                    self.model_id_loaded = actual_identifier_to_use
                    self.is_custom_loaded = False # –≠—Ç–æ –±—ã–ª–∞ HF –º–æ–¥–µ–ª—å
                    return True
                except Exception as e_download_and_load:
                    self._log(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ LayoutLM ('{actual_identifier_to_use}') –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e_download_and_load}")
                    # import traceback; traceback.print_exc() # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
                    self.is_loaded = False
                    return False
            else:
                 # –≠—Ç–æ –±—ã–ª–∞ –ª–∏–±–æ –∫–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å (–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å), –ª–∏–±–æ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º –¥–ª—è HF –º–æ–¥–µ–ª–∏ (–∏ –∫—ç—à –Ω–µ –ø–æ–º–æ–≥)
                self._log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LayoutLM ('{actual_identifier_to_use}'). –ö–∞—Å—Ç–æ–º–Ω–∞—è: {is_loading_custom}, –û—Ñ—Ñ–ª–∞–π–Ω: {offline_mode}. –û—à–∏–±–∫–∞: {e_load}")
                # import traceback; traceback.print_exc()
                self.is_loaded = False
                return False
        return False # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –∏–∑ –ø—É—Ç–µ–π –Ω–µ –ø—Ä–∏–≤–µ–ª –∫ —É—Å–ø–µ—Ö—É
    
    def _log(self, message):
        # –ü—Ä–æ—Å—Ç–æ–π –ª–æ–≥–≥–µ—Ä, –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ logging.info –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å callback
        print(f"LayoutLMProcessor: {message}")

    def process_image(self, image_path, ocr_lang=None, custom_prompt=None):
        if not self.is_loaded:
            print("–û–®–ò–ë–ö–ê: LayoutLMProcessor.process_image –≤—ã–∑–≤–∞–Ω, –Ω–æ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            error_data = {"note_gemini": "–û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å LayoutLM –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞."}
            return InvoiceFormatter.format_invoice_data(error_data)

        lang = ocr_lang if ocr_lang else app_config.DEFAULT_TESSERACT_LANG
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        is_pdf = image_path.lower().endswith('.pdf')
        temp_dir = None
        temp_image_path = None
        
        try:
            if is_pdf:
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                try:
                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    temp_dir = tempfile.mkdtemp()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ poppler
                    poppler_path = app_config.POPPLER_PATH if hasattr(app_config, 'POPPLER_PATH') else None
                    
                    print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è LayoutLM: {image_path}")
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É)
                    images = convert_from_path(
                        image_path, 
                        dpi=300, 
                        first_page=1, 
                        last_page=1,
                        poppler_path=poppler_path
                    )
                    
                    if not images:
                        print(f"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path}")
                        error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF: {os.path.basename(image_path)}."}
                        return InvoiceFormatter.format_invoice_data(error_data)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    temp_image_path = os.path.join(temp_dir, "temp_layoutlm_page.jpg")
                    images[0].save(temp_image_path, "JPEG")
                    print(f"PDF —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {temp_image_path}")
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    text, words = self.ocr_processor.process_image(temp_image_path, lang=lang)
                except Exception as e:
                    print(f"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF —Ñ–∞–π–ª: {e}")
                    import traceback
                    traceback.print_exc()
                    error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {str(e)}"}
                    return InvoiceFormatter.format_invoice_data(error_data)
            else:
                # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OCR
                text, words = self.ocr_processor.process_image(image_path, lang=lang)

            if not words:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å–ª–æ–≤–∞ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {image_path} —Å —è–∑—ã–∫–æ–º {lang}")
                error_data = {"note_gemini": f"OCR –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ ({os.path.basename(image_path)})."}
                return InvoiceFormatter.format_invoice_data(error_data)
            
            try:
                # –î–ª—è PDF –∏—Å–ø–æ–ª—å–∑—É–µ–º temp_image_path, –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - image_path
                actual_image_path = temp_image_path if is_pdf else image_path
                print(f"–û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è LayoutLM: {actual_image_path}")
                image = Image.open(actual_image_path).convert("RGB")
                width, height = image.size
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {actual_image_path} –≤ LayoutLMProcessor: {e}")
                error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {os.path.basename(image_path)}."}
                return InvoiceFormatter.format_invoice_data(error_data)

            word_texts = [word['text'] for word in words]
            raw_boxes = [[word['x'], word['y'], word['x'] + word['width'], word['y'] + word['height']] for word in words]
            normalized_boxes = [self._normalize_box(box, width, height) for box in raw_boxes]
            
            try:
                encoding = self.processor(
                    image, 
                    word_texts,
                    boxes=normalized_boxes,
                    return_tensors="pt",
                    truncation=True,
                    padding="max_length", 
                    max_length=512 
                ).to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(**encoding)
                    
                predictions = outputs.logits.argmax(dim=2)
                id2label = {int(k):v for k,v in self.model.config.id2label.items()} # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –∫–ª—é—á–∏ - int
                word_data_decoded = self._decode_predictions(encoding, predictions, id2label, words, normalized_boxes)

                # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                print(f"DEBUG LayoutLM: –ù–∞–π–¥–µ–Ω–æ {len(word_data_decoded)} —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤")
                if word_data_decoded:
                    print("DEBUG LayoutLM: –ü–µ—Ä–≤—ã–µ 10 —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤:")
                    for i, (word, label, box) in enumerate(word_data_decoded[:10]):
                        print(f"  {i+1}. '{word}' -> {label} (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {box})")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª—è —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Ç–æ–∫
                company_name = self._extract_field(word_data_decoded, 'COMPANY_NAME')
                if not company_name:
                    company_name = self._extract_field(word_data_decoded, 'COMPANY')
                
                invoice_number = self._extract_field(word_data_decoded, 'INVOICE_NUMBER')
                
                invoice_date = self._extract_field(word_data_decoded, 'INVOICE_DATE')
                if not invoice_date:
                    invoice_date = self._extract_field(word_data_decoded, 'DATE')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É–º–º—É —Å —É—á–µ—Ç–æ–º —Ä—É—Å—Å–∫–∏—Ö –º–µ—Ç–æ–∫
                total_amount = self._extract_field(word_data_decoded, 'TOTAL')
                if not total_amount:
                    total_amount = self._extract_field(word_data_decoded, 'AMOUNT')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É–º–º—É –±–µ–∑ –ù–î–° (—Ä—É—Å—Å–∫–∏–µ –º–µ—Ç–∫–∏)
                amount_without_vat = self._extract_field(word_data_decoded, '–°–£–ú–ú–ê_–ë–ï–ó_–ù–î–°')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ù–î–° (—Ä—É—Å—Å–∫–∏–µ –º–µ—Ç–∫–∏)
                vat_rate = self._extract_field(word_data_decoded, '–ù–î–°_%')
                
                invoice_data = {
                    'company': company_name,
                    'inn': self._extract_field(word_data_decoded, 'COMPANY_INN'),
                    'invoice_number': invoice_number,
                    'date': invoice_date,
                    'total_amount': total_amount,
                    'amount_without_vat': amount_without_vat,
                    'vat_percent': vat_rate,
                    'currency': 'RUB', 
                    'items': [], 
                    'note_gemini': "–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é LayoutLMv3"
                }

                # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
                print(f"DEBUG LayoutLM: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø–æ–ª—è:")
                for field, value in invoice_data.items():
                    if field not in ['items', 'currency']:
                        print(f"  {field}: '{value}'")
                invoice_data['currency'] = self._extract_currency(invoice_data, word_data_decoded)

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
                try:
                    table_data = {
                        'words': word_texts,
                        'boxes': normalized_boxes,
                        'labels': [id2label.get(idx.item(), 'O') for idx in predictions[0][:len(word_texts)]]
                    }
                    
                    print(f"DEBUG: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤: words={len(table_data['words'])}, boxes={len(table_data['boxes'])}, labels={len(table_data['labels'])}")
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–∞—Ö –∏–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    items = extract_table_items_from_layoutlm(table_data)
                    print(f"DEBUG: –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(items)}")
                    logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã")
                    logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã: {items}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if items:
                        invoice_data['items'] = items
                except Exception as e:
                    print(f"DEBUG: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
                    import traceback
                    traceback.print_exc()

                return InvoiceFormatter.format_invoice_data(invoice_data)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ LayoutLMProcessor ({self.model_id_loaded}): {e}")
                import traceback
                traceback.print_exc()
                error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ LayoutLM: {e}"}
                return InvoiceFormatter.format_invoice_data(error_data)
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
            if temp_dir:
                try:
                    import shutil
                    shutil.rmtree(temp_dir, ignore_errors=True)
                    print(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–¥–∞–ª–µ–Ω–∞: {temp_dir}")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {e}")

    def _normalize_box(self, box, width, height):
        x0, y0, x1, y1 = box
        return [
            min(max(0, int(1000 * (x0 / width))), 1000),
            min(max(0, int(1000 * (y0 / height))), 1000),
            min(max(0, int(1000 * (x1 / width))), 1000),
            min(max(0, int(1000 * (y1 / height))), 1000)
        ]

    def _decode_predictions(self, encoding, predictions, id2label, original_ocr_words, original_normalized_boxes):
        word_labels = {}
        for i, pred_index in enumerate(predictions[0].tolist()):
            label = id2label.get(pred_index, 'O') 
            word_idx = encoding.word_ids(batch_index=0)[i]
            if word_idx is None or label == 'O':
                continue
            if word_idx not in word_labels:
                word_labels[word_idx] = []
            word_labels[word_idx].append(label)

        decoded_results = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª–∏–Ω—É original_ocr_words –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–∏, —Ç–∞–∫ –∫–∞–∫ word_ids –º–æ–≥—É—Ç —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ —ç—Ç–∏ –∏–Ω–¥–µ–∫—Å—ã
        for idx in range(len(original_ocr_words)):
            word_info = original_ocr_words[idx]
            word_text = word_info['text']
            # –ë–æ–∫—Å –±–µ—Ä–µ–º –∏–∑ original_normalized_boxes –ø–æ —Ç–æ–º—É –∂–µ –∏–Ω–¥–µ–∫—Å—É
            word_box = original_normalized_boxes[idx] if idx < len(original_normalized_boxes) else [0,0,0,0]
            
            labels_for_this_word = word_labels.get(idx, ['O'])
            final_label_base = 'O'
            for lbl in labels_for_this_word:
                if lbl.startswith('B-'):
                    final_label_base = lbl.split('-')[-1]
                    break
                elif lbl.startswith('I-') and final_label_base == 'O': 
                    final_label_base = lbl.split('-')[-1]
            
            if final_label_base != 'O':
                decoded_results.append((word_text, final_label_base, word_box))
        return decoded_results

    def _extract_field(self, word_data, target_label_base):
        extracted_words = []
        try:
            word_data_sorted = sorted(word_data, key=lambda item: (item[2][1], item[2][0])) 
        except IndexError:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ word_data –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –±–æ–∫—Å–æ–≤ –≤ _extract_field.")
            word_data_sorted = word_data

        for word_text, label_base, box in word_data_sorted:
            if label_base.upper() == target_label_base.upper():
                extracted_words.append(word_text)
        return " ".join(extracted_words)

    def _extract_currency(self, parsed_fields, word_data):
        total_str = parsed_fields.get('total_amount', '')
        if '‚ÇΩ' in total_str or '—Ä—É–±' in total_str.lower(): return 'RUB'
        if '$' in total_str: return 'USD'
        if '‚Ç¨' in total_str: return 'EUR'
        currency_from_label = self._extract_field(word_data, 'CURRENCY')
        if currency_from_label.upper() in ['RUB', '–†–£–ë', '‚ÇΩ'] : return 'RUB'
        return 'RUB' 

    def get_full_prompt(self, custom_prompt_text=None):
        base_prompt = custom_prompt_text if custom_prompt_text else settings_manager.get_string('Prompts', 'layoutlm_prompt', "–†–∞—Å–ø–æ–∑–Ω–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è.")
        full_prompt = f"""
====== –°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø (–ù–ï –û–¢–û–ë–†–ê–ñ–ê–ï–¢–°–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Æ) ======
–ú–æ–¥–µ–ª—å: LayoutLMv3 ({self.model_id_loaded})
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OCR: –î–∞ (Tesseract OCR)
–Ø–∑—ã–∫ OCR: {settings_manager.get_string('OCR', 'language', app_config.DEFAULT_TESSERACT_LANG)}
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: –î–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0-1000
–ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ —Ç–µ–∫—Å—Ç—É: –î–∞
====== –ö–û–ù–ï–¶ –°–ò–°–¢–ï–ú–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò ======

====== –ë–ê–ó–û–í–´–ô –ü–†–û–ú–ü–¢ –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• ======
{base_prompt}
====== –ö–û–ù–ï–¶ –ë–ê–ó–û–í–û–ì–û –ü–†–û–ú–ü–¢–ê ======

====== –û–ñ–ò–î–ê–ï–ú–´–ï –ü–û–õ–Ø –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø (–ø—Ä–∏–º–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏ –¥—Ä—É–≥–∏–µ) ======
- COMPANY (–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞/–ø—Ä–æ–¥–∞–≤—Ü–∞)
- INVOICE_ID (–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞/–¥–æ–∫—É–º–µ–Ω—Ç–∞)
- DATE (–î–∞—Ç–∞ —Å—á–µ—Ç–∞/–¥–æ–∫—É–º–µ–Ω—Ç–∞)
- TOTAL (–û–±—â–∞—è —Å—É–º–º–∞ –ø–æ —Å—á–µ—Ç—É)
- CURRENCY (–í–∞–ª—é—Ç–∞)
- (–î—Ä—É–≥–∏–µ –ø–æ–ª—è, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏—Ö —Ä–∞–∑–º–µ—Ç–∏—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä, ADDRESS, VAT, ITEM_NAME, ITEM_QUANTITY, ITEM_PRICE –∏ —Ç.–¥.)
====== –ö–û–ù–ï–¶ –û–ñ–ò–î–ê–ï–ú–´–• –ü–û–õ–ï–ô ======
"""
        return full_prompt


class DonutProcessorImpl(BaseProcessor):
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ Donut.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Donut –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ OCR.
    """
    
    def __init__(self, model_id):
        print("DEBUG: DonutProcessorImpl.__init__ called")
        self.model_id = model_id
        self.model = None
        self.processor = None
        self.is_loaded = False
        self.task_start_token = "<s_cord-v2>"
    
    def load_model(self, model_id=None):
        try:
            if model_id:
                self.model_id = model_id
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ Donut –º–æ–¥–µ–ª–∏ {self.model_id}...")
            model_cache_dir = os.path.join(app_config.MODELS_PATH, 'donut')
            os.makedirs(model_cache_dir, exist_ok=True)
            offline_mode = app_config.OFFLINE_MODE
            token = app_config.HF_TOKEN

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
            import torch
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"Donut: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

            try:
                self.processor = HfDonutProcessor.from_pretrained(
                    model_cache_dir if offline_mode and os.path.exists(os.path.join(model_cache_dir, 'processor_config.json')) else self.model_id,
                    cache_dir=model_cache_dir, # –£–∫–∞–∑—ã–≤–∞–µ–º cache_dir –∑–¥–µ—Å—å
                    local_files_only=offline_mode,
                    token=token
                )
                self.model = VisionEncoderDecoderModel.from_pretrained(
                    model_cache_dir if offline_mode and os.path.exists(os.path.join(model_cache_dir, 'config.json')) else self.model_id,
                    cache_dir=model_cache_dir, # –£–∫–∞–∑—ã–≤–∞–µ–º cache_dir –∑–¥–µ—Å—å
                    local_files_only=offline_mode,
                    token=token,
                    torch_dtype=torch.float16 if device.type == "cuda" else torch.float32  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU
                )
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                self.model.to(device)
                self.device = device
                print(f"Donut: –ú–æ–¥–µ–ª—å '{self.model_id}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            except Exception as e_direct_load:
                if not offline_mode:
                    print(f"Donut: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å '{self.model_id}' –Ω–∞–ø—Ä—è–º—É—é ({e_direct_load}), –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã –æ—Ç–¥–µ–ª—å–Ω–æ...")
                    required_files = ['config.json', 'pytorch_model.bin', 'processor_config.json', 'tokenizer_config.json', 'special_tokens_map.json', 'sentencepiece.bpe.model']
                    for file_name in required_files:
                        try:
                            hf_hub_download(
                                repo_id=self.model_id, 
                                filename=file_name,
                                cache_dir=model_cache_dir,
                                token=token,
                                force_download=True
                            )
                            print(f"–§–∞–π–ª {file_name} –¥–ª—è Donut –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {model_cache_dir}")
                        except Exception as e_file:
                            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª {file_name} –¥–ª—è Donut ({self.model_id}): {e_file}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –æ–Ω –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω.")
                    
                    self.processor = HfDonutProcessor.from_pretrained(model_cache_dir, local_files_only=True, token=token)
                    self.model = VisionEncoderDecoderModel.from_pretrained(model_cache_dir, local_files_only=True, token=token)
                    print(f"Donut: –ú–æ–¥–µ–ª—å '{self.model_id}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –∫—ç—à–∞ –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤.")
                else:
                    print(f"Donut: –û—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º, –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å '{self.model_id}' –∏–∑ –∫—ç—à–∞ ({e_direct_load}).")
                    self.is_loaded = False
                    return False
            
            if self.task_start_token not in self.processor.tokenizer.get_vocab():
                print(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ {self.task_start_token} –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä Donut...")
                added_tokens = self.processor.tokenizer.add_tokens(self.task_start_token, special_tokens=True)
                if added_tokens > 0:
                    self.model.resize_token_embeddings(len(self.processor.tokenizer))
                    print(f"–¢–æ–∫–µ–Ω {self.task_start_token} –¥–æ–±–∞–≤–ª–µ–Ω, —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–¥–µ–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
                else:
                    print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¢–æ–∫–µ–Ω {self.task_start_token} –Ω–µ –±—ã–ª –¥–æ–±–∞–≤–ª–µ–Ω (—É–∂–µ –µ—Å—Ç—å?).")
            
            self.is_loaded = True
            return True
        except Exception as e:
            print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ Donut ({self.model_id}): {e}")
            import traceback
            traceback.print_exc()
            self.is_loaded = False
            return False

    def process_image(self, image_path, ocr_lang=None, custom_prompt=None):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Donut –º–æ–¥–µ–ª–∏.
        ocr_lang –∏ custom_prompt –∑–¥–µ—Å—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏,
        –Ω–æ custom_prompt (–µ—Å–ª–∏ —ç—Ç–æ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞) –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è self.task_start_token.
        """
        if not self.is_loaded:
            print("–û–®–ò–ë–ö–ê: DonutProcessor.process_image –≤—ã–∑–≤–∞–Ω, –Ω–æ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            if not self.load_model(): # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å —Ç–µ–∫—É—â–∏–º self.model_id
                print("–û–®–ò–ë–ö–ê: DonutProcessor.process_image: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Donut.")
                error_data = {"note_gemini": "–û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å Donut –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ / –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å."}
                return InvoiceFormatter.format_invoice_data(error_data)

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–º
            if image_path.lower().endswith('.pdf'):
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é —á–µ—Ä–µ–∑ pdf2image
                try:
                    from pdf2image import convert_from_path
                    import tempfile
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ poppler
                    poppler_path = settings_manager.get_string('Tools', 'poppler_path', '')
                    if poppler_path and os.path.exists(poppler_path):
                        poppler_path = os.path.join(poppler_path, 'bin') if not poppler_path.endswith('bin') else poppler_path
                    else:
                        poppler_path = None
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    pages = convert_from_path(
                        image_path, 
                        first_page=1, 
                        last_page=1,
                        dpi=200,  # –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è OCR
                        poppler_path=poppler_path
                    )
                    
                    if pages:
                        image = pages[0].convert("RGB")
                        print(f"Donut: PDF –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image.size}")
                    else:
                        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF")
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF {image_path} –≤ DonutProcessor: {e}")
                    error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF: {os.path.basename(image_path)}"}
                    return InvoiceFormatter.format_invoice_data(error_data)
            else:
                # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                image = Image.open(image_path).convert("RGB")
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path} –≤ DonutProcessor: {e}")
            error_data = {"note_gemini": f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {os.path.basename(image_path)}."}
            return InvoiceFormatter.format_invoice_data(error_data)

        # –î–ª—è –º–æ–¥–µ–ª–∏ CORD-v2 –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π task token
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º custom_prompt, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        task_prompt_to_use = self.task_start_token
        
        print(f"DonutProcessor: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è task_prompt: {task_prompt_to_use}")

        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
            pixel_values = self.processor(image, return_tensors="pt").pixel_values
            decoder_input_ids = self.processor.tokenizer(task_prompt_to_use, add_special_tokens=False, return_tensors="pt").input_ids
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –Ω–∞ —Ç–æ –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
            device = getattr(self, 'device', torch.device('cpu'))
            pixel_values = pixel_values.to(device)
            decoder_input_ids = decoder_input_ids.to(device)
            
            print(f"Donut: –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ {device}...")
            start_time = time.time()
            
            # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            max_length = min(512, self.model.decoder.config.max_position_embeddings)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–≤–æ–¥–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è CORD-v2
            with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                outputs = self.model.generate(
                    pixel_values,
                    decoder_input_ids=decoder_input_ids,
                    max_length=max_length,  # –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
                    min_length=10,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
                    pad_token_id=self.processor.tokenizer.pad_token_id,
                    eos_token_id=self.processor.tokenizer.eos_token_id,
                    use_cache=True,
                    num_beams=1,  # Greedy decoding –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    do_sample=False,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                    bad_words_ids=[[self.processor.tokenizer.unk_token_id]] if self.processor.tokenizer.unk_token_id is not None else None,
                    return_dict_in_generate=True,
                    # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç —Å num_beams=1
                    repetition_penalty=1.1,  # –ò–∑–±–µ–≥–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
                )
            
            generation_time = time.time() - start_time
            print(f"Donut: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {generation_time:.2f} —Å–µ–∫")
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            sequence = self.processor.batch_decode(outputs.sequences)[0]
            sequence = sequence.replace(self.processor.tokenizer.eos_token, "").replace(self.processor.tokenizer.pad_token, "")
            # –£–±–∏—Ä–∞–µ–º task_prompt –∏–∑ –Ω–∞—á–∞–ª–∞, –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å
            if sequence.startswith(task_prompt_to_use):
                sequence = sequence[len(task_prompt_to_use):]
            
            # –ü–∞—Ä—Å–∏–Ω–≥ JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏
            # parsed_json = self._parse_json_output(sequence) # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é
            cleaned_sequence = self._clean_json_string_for_donut(sequence)
            parsed_json = json.loads(cleaned_sequence)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∑–∞–º–µ—Ç–∫—É –∏ –≤–æ–∑–º–æ–∂–Ω–æ –∏—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            parsed_json['note_gemini'] = f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é Donut ({self.model_id})"
            parsed_json['raw_response_donut'] = cleaned_sequence 
            
            return InvoiceFormatter.format_invoice_data(parsed_json)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ DonutProcessor ({self.model_id}): {e}")
            import traceback
            traceback.print_exc()
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –æ—à–∏–±–∫–æ–π, —á—Ç–æ–±—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –ø–∞–¥–∞–ª–æ
            error_data = {
                "note_gemini": f"–û—à–∏–±–∫–∞ Donut: {str(e)}",
                "raw_response_donut": sequence if 'sequence' in locals() else "–û—à–∏–±–∫–∞ –¥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"
            }
            return InvoiceFormatter.format_invoice_data(error_data)

    # –ù–û–í–´–ô –ú–ï–¢–û–î –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ JSON, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ç–æ—Ç, —á—Ç–æ –≤ GeminiProcessor
    def _clean_json_string_for_donut(self, s: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ Donut CORD-v2, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è —Ç–µ–≥–∏ –≤ JSON."""
        s = s.strip()
        
        # –°–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º –≤—Å–µ <unk> —Ç–æ–∫–µ–Ω—ã
        s = re.sub(r'<unk>', '', s)
        
        # –ú–æ–¥–µ–ª—å CORD-v2 –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ–≥–æ–≤, –∞ –Ω–µ JSON
        # –ü—Ä–∏–º–µ—Ä: <s_company>–û–û–û "–ö–æ–º–ø–∞–Ω–∏—è"</s_company><s_total>1000.00</s_total>
        # –ù—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —ç—Ç–æ –≤ JSON
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–≥–∏ CORD-v2
        if '<s_' in s and '</s_' in s:
            return self._parse_cord_tags_to_json(s)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—ã—á–Ω—ã–π JSON, –ø—ã—Ç–∞–µ–º—Å—è –µ–≥–æ –∏–∑–≤–ª–µ—á—å
        match_md_json = re.search(r"```json\s*(.*?)\s*```", s, re.DOTALL | re.IGNORECASE)
        if match_md_json:
            return match_md_json.group(1).strip()
        
        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª { –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π }
        try:
            start_index = s.index('{')
            end_index = s.rindex('}')
            potential_json = s[start_index : end_index + 1]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ JSON
            potential_json = self._fix_common_json_errors(potential_json)
            
            json.loads(potential_json) # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            return potential_json
        except (ValueError, json.JSONDecodeError) as e:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏/—Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–∞–ª–∏–¥–Ω—ã–π JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ Donut: '{s[:200]}...'")
            print(f"–û—à–∏–±–∫–∞ JSON: {e}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ö–æ—Ç—è –±—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
            fallback_data = self._extract_fallback_data(s)
            return json.dumps(fallback_data, ensure_ascii=False)
    
    def _parse_cord_tags_to_json(self, s: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–≥–∏ CORD-v2 –≤ JSON —Ñ–æ—Ä–º–∞—Ç."""
        try:
            # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ —Ç–µ–≥–æ–≤ CORD-v2 –≤ –ø–æ–ª—è JSON
            cord_to_json_mapping = {
                's_company': 'company',
                's_nm': 'company',  # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
                's_total': 'total_amount',
                's_total_price': 'total_amount',
                's_subtotal_price': 'subtotal_amount',
                's_date': 'date',
                's_invoice_number': 'invoice_number',
                's_invoice_id': 'invoice_number',
                's_address': 'address',
                's_menu': 'items',
                's_cnt': 'quantity',
                's_price': 'price',
                's_cashprice': 'cash_amount',
                's_changeprice': 'change_amount',
            }
            
            result = {}
            
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–µ–≥–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ <s_tag>content</s_tag>
            tag_pattern = r'<s_([^>]+)>(.*?)</s_\1>'
            matches = re.findall(tag_pattern, s, re.DOTALL)
            
            for tag, content in matches:
                # –û—á–∏—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                content = content.strip()
                content = re.sub(r'<unk>', '', content)
                content = re.sub(r'[^\x20-\x7E\u0400-\u04FF\u0100-\u017F.,\-\d]', '', content)
                
                if content:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                    # –ú–∞–ø–ø–∏–º —Ç–µ–≥ –≤ JSON –ø–æ–ª–µ
                    json_field = cord_to_json_mapping.get(tag, tag)
                    result[json_field] = content
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if not result:
                result = {
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–≥–æ–≤ CORD-v2',
                    'raw_text': s[:500] + '...' if len(s) > 500 else s
                }
            
            return json.dumps(result, ensure_ascii=False)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–≥–æ–≤ CORD-v2: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º fallback —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            fallback_data = {
                'error': f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–≥–æ–≤: {str(e)}',
                'raw_text': s[:500] + '...' if len(s) > 500 else s
            }
            return json.dumps(fallback_data, ensure_ascii=False)
    
    def _fix_common_json_errors(self, json_str: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON —Å—Ç—Ä–æ–∫–∞—Ö –æ—Ç Donut"""
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã <unk> –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –ø–æ—è–≤–ª—è—é—Ç—Å—è –≤ –≤—ã–≤–æ–¥–µ Donut
        json_str = re.sub(r'<unk>', '', json_str)
        
        # –£–±–∏—Ä–∞–µ–º trailing commas
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –∫–∞–≤—ã—á–∫–∏
        json_str = re.sub(r':\s*"([^"]*)"([^,}\]]*)', r': "\1"', json_str)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –ø–æ—Å–ª–µ –∑–Ω–∞—á–µ–Ω–∏–π
        json_str = re.sub(r':\s*"([^"]*)"[^,}\]]*([,}\]])', r': "\1"\2', json_str)
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        json_str = re.sub(r'[^\x20-\x7E\u0400-\u04FF{}",:\[\]0-9.]', '', json_str)
        
        return json_str
    
    def _extract_fallback_data(self, text: str) -> dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –∫–∞–∫ fallback"""
        # –°–Ω–∞—á–∞–ª–∞ –æ—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Å–∏–º–≤–æ–ª–æ–≤ <unk> –∏ –¥—Ä—É–≥–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        cleaned_text = re.sub(r'<unk>', '', text)
        cleaned_text = re.sub(r'[^\x20-\x7E\u0400-\u04FF]', ' ', cleaned_text)
        
        fallback_data = {}
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π
        patterns = {
            'company': [r'company["\s]*:[\s]*["\s]*([^"}\n,]+)', r'–ø–æ—Å—Ç–∞–≤—â–∏–∫["\s]*:[\s]*["\s]*([^"}\n,]+)'],
            'invoice_number': [r'invoice[_\s]*(?:id|number)["\s]*:[\s]*["\s]*([^"}\n,]+)', r'–Ω–æ–º–µ—Ä["\s]*:[\s]*["\s]*([^"}\n,]+)'],
            'date': [r'date["\s]*:[\s]*["\s]*([^"}\n,]+)', r'–¥–∞—Ç–∞["\s]*:[\s]*["\s]*([^"}\n,]+)'],
            'total_amount': [r'total["\s]*:[\s]*["\s]*([^"}\n,]+)', r'—Å—É–º–º–∞["\s]*:[\s]*["\s]*([^"}\n,]+)'],
            'currency': [r'currency["\s]*:[\s]*["\s]*([^"}\n,]+)', r'–≤–∞–ª—é—Ç–∞["\s]*:[\s]*["\s]*([^"}\n,]+)']
        }
        
        for field, field_patterns in patterns.items():
            for pattern in field_patterns:
                match = re.search(pattern, cleaned_text, re.IGNORECASE)
                if match:
                    value = match.group(1).strip().strip('"').strip()
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è
                    value = re.sub(r'<unk>', '', value)
                    value = re.sub(r'[^\x20-\x7E\u0400-\u04FF]', '', value).strip()
                    if value and value != '<unk>':
                        fallback_data[field] = value
                        break
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –æ—à–∏–±–∫–æ–π
        if not fallback_data:
            fallback_data = {
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ Donut',
                'raw_text': cleaned_text[:500] + '...' if len(cleaned_text) > 500 else cleaned_text
            }
        
        return fallback_data

    # def _parse_json_output(self, output_string):
    #     # –≠–¢–û–¢ –ú–ï–¢–û–î –ë–û–õ–¨–®–ï –ù–ï –ù–£–ñ–ï–ù, –ó–ê–ú–ï–ù–ï–ù –ù–ê _clean_json_string_for_donut –∏ json.loads
    #     try:
    #         # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
    #         # –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã.
    #         return json.loads(output_string)
    #     except json.JSONDecodeError as e:
    #         print(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ –≤—ã–≤–æ–¥–∞ Donut: {e}")
    #         print(f"–°—Ç—Ä–æ–∫–∞, –≤—ã–∑–≤–∞–≤—à–∞—è –æ—à–∏–±–∫—É: {output_string}")
    #         # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—à–∏–±–∫–∏
    #         return {"error": "JSONDecodeError", "raw_output": output_string}

    def get_full_prompt(self, custom_prompt=None):
        base_prompt = custom_prompt if custom_prompt else settings_manager.get_string('Prompts', 'donut_prompt', "–†–∞—Å–ø–æ–∑–Ω–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è.")
        full_prompt = f"""
====== –°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø (–ù–ï –û–¢–û–ë–†–ê–ñ–ê–ï–¢–°–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Æ) ======
–ú–æ–¥–µ–ª—å: Donut ({self.model_id})
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OCR: –ù–µ—Ç
–Ø–∑—ã–∫ OCR: {settings_manager.get_string('OCR', 'language', app_config.DEFAULT_TESSERACT_LANG)}
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: –ù–µ—Ç
–ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ —Ç–µ–∫—Å—Ç—É: –ù–µ—Ç
====== –ö–û–ù–ï–¶ –°–ò–°–¢–ï–ú–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò ======

====== –ë–ê–ó–û–í–´–ô –ü–†–û–ú–ü–¢ –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• ======
{base_prompt}
====== –ö–û–ù–ï–¶ –ë–ê–ó–û–í–û–ì–û –ü–†–û–ú–ü–¢–ê ======

====== –û–ñ–ò–î–ê–ï–ú–´–ï –ü–û–õ–Ø –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø (–ø—Ä–∏–º–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏ –¥—Ä—É–≥–∏–µ) ======
- COMPANY (–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞/–ø—Ä–æ–¥–∞–≤—Ü–∞)
- INVOICE_ID (–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞/–¥–æ–∫—É–º–µ–Ω—Ç–∞)
- DATE (–î–∞—Ç–∞ —Å—á–µ—Ç–∞/–¥–æ–∫—É–º–µ–Ω—Ç–∞)
- TOTAL (–û–±—â–∞—è —Å—É–º–º–∞ –ø–æ —Å—á–µ—Ç—É)
- CURRENCY (–í–∞–ª—é—Ç–∞)
- (–î—Ä—É–≥–∏–µ –ø–æ–ª—è, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏—Ö —Ä–∞–∑–º–µ—Ç–∏—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä, ADDRESS, VAT, ITEM_NAME, ITEM_QUANTITY, ITEM_PRICE –∏ —Ç.–¥.)
====== –ö–û–ù–ï–¶ –û–ñ–ò–î–ê–ï–ú–´–• –ü–û–õ–ï–ô ======
"""
        return full_prompt


class InvoiceFormatter:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å—á–µ—Ç–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç—Ä–µ–±—É–µ–º—ã–º –ø—Ä–æ–º—Ç–æ–º.
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
    """
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ä–∞—Å—Ö–æ–¥–æ–≤
    EXPENSE_CATEGORIES = [
        "IT and Software Costs",
        "Telephone and Communication",
        "Office Supplies",
        "Travel and Accommodation",
        "Marketing and Advertising",
        "Service Fees",
        "Subscriptions and Memberships",
        "Training and Education",
        "Utilities and Rent",
        "Professional Services"
    ]
    
    # --- NEW: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã --- 
    @staticmethod
    def format_number_with_comma(number_str, decimal_places=2):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É —Å –∑–∞–ø—è—Ç–æ–π –≤–º–µ—Å—Ç–æ —Ç–æ—á–∫–∏.
        –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Ç–æ—á–∫–æ–π.
        
        Args:
            number_str (str): –°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —á–∏—Å–ª–∞
            decimal_places (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2)
            
        Returns:
            str: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ —Å –∑–∞–ø—è—Ç–æ–π –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏–ª–∏ 'N/A'
        """
        if not number_str:
            return "N/A"
            
        try:
            normalized_str = str(number_str).replace(',', '.')
            cleaned_str = re.sub(r'[^\d\.]', '', normalized_str)
            if cleaned_str.count('.') > 1:
                parts = cleaned_str.split('.')
                cleaned_str = parts[0] + '.' + ''.join(parts[1:]) 
            
            value = float(cleaned_str)
            format_string = "{:." + str(decimal_places) + "f}"
            return format_string.format(value).replace('.', ',')
        except (ValueError, TypeError):
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{number_str}' –≤ —á–∏—Å–ª–æ.")
            return "N/A" 
    
    @staticmethod
    def format_date(date_str):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç DD.MM.YYYY.
        """
        if not date_str:
            return "N/A"
            
        date_patterns = [
            r'(\d{1,2})[\/\.\-](\d{1,2})[\/\.\-](\d{2,4})',  # DD/MM/YYYY
            r'(\d{4})[\/\.\-](\d{1,2})[\/\.\-](\d{1,2})',  # YYYY/MM/DD
            r'(\d{1,2})[\s]([–∞-—è–ê-–Ø]+)[\s](\d{2,4})'  # DD –º–µ—Å—è—Ü YYYY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, date_str)
            if match:
                groups = match.groups()
                if len(groups[0]) == 4:
                    year, month, day = groups
                else:
                    day, month, year = groups
                    if not month.isdigit():
                        month_map = {
                            '—è–Ω–≤–∞—Ä': '01', '—Ñ–µ–≤—Ä–∞–ª': '02', '–º–∞—Ä—Ç': '03', '–∞–ø—Ä–µ–ª': '04',
                            '–º–∞': '05', '–º–∞–π': '05', '–∏—é–Ω': '06', '–∏—é–ª': '07',
                            '–∞–≤–≥—É—Å—Ç': '08', '—Å–µ–Ω—Ç—è–±—Ä': '09', '–æ–∫—Ç—è–±—Ä': '10',
                            '–Ω–æ—è–±—Ä': '11', '–¥–µ–∫–∞–±—Ä': '12'
                        }
                        for ru_month, num in month_map.items():
                            if ru_month in month.lower():
                                month = num
                                break
                
                if len(year) == 2:
                    year = '20' + year
                day = day.zfill(2)
                month = str(month).zfill(2)
                return f"{day}.{month}.{year}"
        
        return date_str # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, –µ—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ
    
    @staticmethod
    def clean_invoice_number(invoice_number):
        """
        –û—á–∏—â–∞–µ—Ç –Ω–æ–º–µ—Ä —Å—á–µ—Ç–∞ –æ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ (‚Ññ, –°—á–µ—Ç –∏ —Ç.–¥.).
        """
        if not invoice_number or str(invoice_number).upper() == 'N/A':
            return "N/A"
            
        cleaned_number = str(invoice_number).strip()
        prefixes_to_remove = ["—Å—á–µ—Ç ‚Ññ", "—Å—á–µ—Ç no", "—Å—á–µ—Ç n", "—Å—á–µ—Ç", "‚Ññ", "no.", "no", "n"]
        lower_number = cleaned_number.lower()
        
        for prefix in prefixes_to_remove:
            if lower_number.startswith(prefix):
                cleaned_number = cleaned_number[len(prefix):].lstrip()
                break
        
        return cleaned_number if cleaned_number else "N/A"
    
    @staticmethod
    def classify_expense(description, items):
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ä–∞—Å—Ö–æ–¥ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
        """
        text = str(description).lower()
        for item in items:
            if isinstance(item, dict) and 'name' in item:
                text += ' ' + str(item['name']).lower()
        
        keywords = {
            "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ç–æ–∫–∞—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏": ['—Ç–æ–∫–∞—Ä–Ω', '—Ä–µ–∑–µ—Ü', '–ø–ª–∞—Å—Ç–∏–Ω', '–¥–µ—Ä–∂–∞–≤–∫', 'sbwr', 'ccmt', 'cnga', 'dclnr', 'sbmt', 'tdjx', 'tpgx', 'wnmg'],
            "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ñ—Ä–µ–∑–µ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏": ['—Ñ—Ä–µ–∑', '—Å–≤–µ—Ä–ª', '–∫–æ–Ω—Ü–µ–≤–∞—è', '–∫–æ—Ä–ø—É—Å–Ω–∞—è'],
            "–†–∞—Å—Ö–æ–¥–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã": ['–∫–ª–µ–π–º', '–º–µ—Ç—á–∏–∫', '–ø–ª–∞—à–∫', '—Ä–∞–∑–≤–µ—Ä—Ç–∫', '–∑–µ–Ω–∫–µ—Ä', '—â–µ—Ç–∫', '–¥–∏—Å–∫', '–∫—Ä—É–≥', '—à–ª–∏—Ñ'],
            "–ü—Ä–æ—á–µ–µ": ['—â—É–ø', '–∏–∑–º–µ—Ä–∏—Ç', '—à—Ç–∞–Ω–≥–µ–Ω', '–º–∏–∫—Ä–æ–º–µ—Ç—Ä']
        }
        
        best_match = "–ü—Ä–æ—á–µ–µ"
        max_matches = 0
        
        for category, words in keywords.items():
            matches = sum(1 for word in words if word in text)
            if matches > max_matches:
                max_matches = matches
                best_match = category
            elif matches > 0 and matches == max_matches and category != "–ü—Ä–æ—á–µ–µ": # –ù–µ–±–æ–ª—å—à–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
                 pass # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Å —Ç–µ–º –∂–µ —á–∏—Å–ª–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                 
        return best_match
    
    @staticmethod
    def format_description(items):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ.
        –ö–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π —Å –∑–∞–ø—è—Ç–æ–π.
        """
        if not items or not isinstance(items, list):
            return "N/A"
            
        descriptions = []
        for item in items:
            if isinstance(item, dict):
                name = item.get('name', '')
                quantity = item.get('quantity', '')
                price = item.get('price', '') # –¶–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
                amount = item.get('amount', '') # –°—É–º–º–∞ –ø–æ –ø–æ–∑–∏—Ü–∏–∏
                
                item_str = str(name)
                if quantity:
                    item_str += f" - {quantity} —à—Ç"
                if amount: # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—É–º–º—É –ø–æ –ø–æ–∑–∏—Ü–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
                    amount_formatted = InvoiceFormatter.format_number_with_comma(amount)
                    item_str += f", {amount_formatted} —Ä—É–±"
                elif price: # –ï—Å–ª–∏ –Ω–µ—Ç —Å—É–º–º—ã, –Ω–æ –µ—Å—Ç—å —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
                    price_formatted = InvoiceFormatter.format_number_with_comma(price)
                    item_str += f", {price_formatted} —Ä—É–±/—à—Ç"
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
                item_str += ";"
                descriptions.append(item_str)
            elif isinstance(item, str):
                # –î–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–æ–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π
                item_str = item.strip()
                if not item_str.endswith(';'):
                    item_str += ";"
                descriptions.append(item_str)
                 
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–æ–≤–∞—Ä—ã —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –≤–º–µ—Å—Ç–æ "; "
        return "\n".join(descriptions) if descriptions else "N/A"
    
    @staticmethod
    def calculate_vat_rate(total_amount, amount_without_vat):
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞–≤–∫—É –ù–î–° –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–π —Å—É–º–º—ã –∏ —Å—É–º–º—ã –±–µ–∑ –ù–î–°.
        """
        try:
            total = float(str(total_amount).replace(',', '.'))
            base = float(str(amount_without_vat).replace(',', '.'))
            
            if base == 0 or total == 0 or abs(total - base) < 0.01: # –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ
                return "0,0"
                
            vat_amount = total - base
            vat_rate = (vat_amount / base) * 100
            
            if 9.5 <= vat_rate < 10.5:
                return "10,0"
            elif 19.5 <= vat_rate < 20.5:
                 return "20,0"

            return f"{vat_rate:.1f}".replace('.', ',')
        except (ValueError, TypeError, ZeroDivisionError):
            return "N/A" 
    # --- –ö–æ–Ω–µ—Ü –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ ---

    @staticmethod
    def format_invoice_data(invoice_data):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—á–µ—Ç–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç—Ä–µ–±—É–µ–º—ã–º –ø—Ä–æ–º—Ç–æ–º.
        
        Args:
            invoice_data (dict): –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å—á–µ—Ç–∞ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç)
            
        Returns:
            dict: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫–ª—é—á–∏ –∫–∞–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ)
        """
        if not invoice_data:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ N/A, —á—Ç–æ–±—ã —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –ª–æ–º–∞–ª–∞—Å—å
            return {
                "‚Ññ —Å—á–µ—Ç–∞": "N/A", "–î–∞—Ç–∞ —Å—á–µ—Ç–∞": "N/A", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "N/A",
                "–ü–æ—Å—Ç–∞–≤—â–∏–∫": "N/A", "–¢–æ–≤–∞—Ä—ã": "N/A", 
                "–°—É–º–º–∞ –±–µ–∑ –ù–î–°": "N/A", "% –ù–î–°": "N/A", "–°—É–º–º–∞ —Å –ù–î–°": "N/A",
                "–í–∞–ª—é—Ç–∞": "N/A", "INN": "N/A", "KPP": "N/A", "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ": "N/A"
            }
            
        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç)
        invoice_number = invoice_data.get('invoice_number', '')
        date_str = invoice_data.get('date', '')
        company = invoice_data.get('company', '')
        
        # NEW: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
        category_gemini = invoice_data.get('category_gemini', '')
        description_gemini = invoice_data.get('description_gemini', '')
        amount_without_vat_gemini = invoice_data.get('amount_without_vat_gemini', '')
        vat_percent_gemini = invoice_data.get('vat_percent_gemini', '')
        note_gemini = invoice_data.get('note_gemini', '')
        
        items = invoice_data.get('items', [])
        total_amount_str = invoice_data.get('total_amount', '0.00')
        currency = invoice_data.get('currency', 'RUB')

        # 1. –ù–æ–º–µ—Ä —Å—á–µ—Ç–∞
        clean_invoice_number = invoice_number.strip()
        if not clean_invoice_number:
            clean_invoice_number = "N/A"

        # 2. –î–∞—Ç–∞ —Å—á–µ—Ç–∞
        formatted_date = date_str.strip()
        if not formatted_date:
            formatted_date = "N/A"

        # 3. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏-–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
        if not company:
            company = "N/A"

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        amount_without_vat_final_str = "N/A"
        vat_percent_final_str = "N/A"

        # 4. –°—É–º–º–∞ –±–µ–∑ –ù–î–°
        if not amount_without_vat_gemini:
            amount_without_vat_gemini = "N/A"

        # 5. –ü—Ä–æ—Ü–µ–Ω—Ç –ù–î–° (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
        if not vat_percent_gemini:
            vat_percent_gemini = "N/A"

        # 6. –û–±—â–∞—è —Å—É–º–º–∞ –∫ –æ–ø–ª–∞—Ç–µ
        if not total_amount_str:
            total_amount_str = "N/A"

        # 7. –í–∞–ª—é—Ç–∞
        if not currency:
            currency = "N/A"

        # 8. –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥
        if not description_gemini:
            description_gemini = "N/A"

        # 9. –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥
        if not items:
            items = "N/A"

        # 10. –û–±—â–∞—è —Å—É–º–º–∞
        # total_float = float(total_amount_str.replace(',', '.')) # –ë–´–õ–û - –ø–∞–¥–∞–µ—Ç –Ω–∞ N/A
        try:
            if total_amount_str and str(total_amount_str).strip().upper() != 'N/A':
                total_float = float(str(total_amount_str).replace(',', '.'))
            else:
                total_float = 0.0 # –ò–ª–∏ None, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ä–∞–∑–ª–∏—á–∞—Ç—å 0 –∏ N/A
        except (ValueError, TypeError):
             total_float = 0.0 # –ï—Å–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å

        # 11. –û–±—â–∞—è —Å—É–º–º–∞ –±–µ–∑ –ù–î–°
        if amount_without_vat_gemini and amount_without_vat_gemini.upper() != 'N/A':
            amount_without_vat_final_str = InvoiceFormatter.format_number_with_comma(amount_without_vat_gemini, decimal_places=2)
            if not (vat_percent_gemini and vat_percent_gemini.upper() != 'N/A'):
                try:
                    amount_without_vat_gemini_float = float(str(amount_without_vat_gemini).replace(',', '.'))
                    if amount_without_vat_gemini_float > 0:
                         vat_percent_final_str = InvoiceFormatter.calculate_vat_rate(total_float, amount_without_vat_gemini_float)
                    else:
                         vat_percent_final_str = "0,0" # –ï—Å–ª–∏ —Å—É–º–º–∞ –±–µ–∑ –ù–î–° = 0, —Ç–æ –∏ % = 0
                except (ValueError, TypeError):
                    pass # –û—Å—Ç–∞–≤–∏–º N/A –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        elif total_float > 0:
            if vat_percent_gemini and vat_percent_gemini.upper() != 'N/A':
                try:
                    vat_rate_str = InvoiceFormatter.format_number_with_comma(vat_percent_gemini.replace('%','').strip(), decimal_places=1)
                    if vat_rate_str != 'N/A':
                        vat_rate_float = float(vat_rate_str.replace(',', '.'))
                        if vat_rate_float >= 0:
                            calculated_amount_without_vat = total_float / (1 + vat_rate_float / 100)
                            amount_without_vat_final_str = InvoiceFormatter.format_number_with_comma(calculated_amount_without_vat, decimal_places=2)
                            vat_percent_final_str = vat_rate_str
                except (ValueError, TypeError):
                     pass 

        if vat_percent_gemini and vat_percent_gemini.upper() != 'N/A':
            vat_percent_final_str = InvoiceFormatter.format_number_with_comma(vat_percent_gemini.replace('%','').strip(), decimal_places=1)
        elif amount_without_vat_final_str != "N/A" and total_float > 0 and vat_percent_final_str == "N/A":
            try:
                amount_without_vat_float = float(amount_without_vat_final_str.replace(',', '.'))
                if amount_without_vat_float > 0:
                    vat_percent_final_str = InvoiceFormatter.calculate_vat_rate(total_float, amount_without_vat_float)
                else:
                     vat_percent_final_str = "0,0"
            except (ValueError, TypeError):
                 vat_percent_final_str = "N/A"

        if total_float > 0 and amount_without_vat_final_str != "N/A":
             amount_without_vat_float_check = float(amount_without_vat_final_str.replace(',', '.'))
             if abs(total_float - amount_without_vat_float_check) < 0.01:
                 if vat_percent_final_str == "N/A": vat_percent_final_str = "0,0"
        
        if vat_percent_final_str == "N/A":
             pass 
        if amount_without_vat_final_str == "N/A":
             pass 

        # ... (–æ—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å –º–µ—Ç–æ–¥–∞ format_invoice_data) ...
        formatted_total = InvoiceFormatter.format_number_with_comma(total_float, decimal_places=2)
        final_currency = currency if currency and currency.upper() != 'N/A' else 'RUB'
        note = note_gemini if note_gemini and note_gemini.upper() != 'N/A' else "N/A"
        
        result = {
            "‚Ññ —Å—á–µ—Ç–∞": clean_invoice_number,
            "–î–∞—Ç–∞ —Å—á–µ—Ç–∞": formatted_date,
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": category_gemini,
            "–ü–æ—Å—Ç–∞–≤—â–∏–∫": company,
            "–¢–æ–≤–∞—Ä—ã": description_gemini,
            "–°—É–º–º–∞ –±–µ–∑ –ù–î–°": amount_without_vat_final_str,
            "% –ù–î–°": vat_percent_final_str,
            "–°—É–º–º–∞ —Å –ù–î–°": formatted_total,
            "–í–∞–ª—é—Ç–∞": final_currency,
            "INN": invoice_data.get('inn', 'N/A'),
            "KPP": invoice_data.get('kpp', 'N/A'),
            "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ": note
        }
        
        return result 